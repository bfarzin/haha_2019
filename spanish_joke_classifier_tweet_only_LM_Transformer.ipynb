{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the tweets for the updated vocab, test classifer on humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farzin/haha_2019\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "import sentencepiece as spm #https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python code Examples (testing out tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/rnn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_df = pd.read_csv('./data/haha_2019_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>votes_no</th>\n",
       "      <th>votes_1</th>\n",
       "      <th>votes_2</th>\n",
       "      <th>votes_3</th>\n",
       "      <th>votes_4</th>\n",
       "      <th>votes_5</th>\n",
       "      <th>funniness_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705196579758583809</td>\n",
       "      <td>Niveles de retraso mental: \\r\\n\\r\\n— Bajo.\\r\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>678040651817213952</td>\n",
       "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>546750892213829633</td>\n",
       "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>965807211292364801</td>\n",
       "      <td>No se porqué me hago la cabeza deooos</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638403841839484928</td>\n",
       "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  705196579758583809  Niveles de retraso mental: \\r\\n\\r\\n— Bajo.\\r\\n...   \n",
       "1  678040651817213952  —Vamos Luke desenfunda tu sable, demuestra tu ...   \n",
       "2  546750892213829633  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...   \n",
       "3  965807211292364801              No se porqué me hago la cabeza deooos   \n",
       "4  638403841839484928  Quisiera saber que hago durante la siesta de l...   \n",
       "\n",
       "   is_humor  votes_no  votes_1  votes_2  votes_3  votes_4  votes_5  \\\n",
       "0         1         1        2        2        0        0        0   \n",
       "1         1         1        3        0        1        0        0   \n",
       "2         1         0        2        1        0        1        1   \n",
       "3         0         3        0        0        0        0        0   \n",
       "4         0         4        0        1        0        0        0   \n",
       "\n",
       "   funniness_average  \n",
       "0                1.5  \n",
       "1                1.5  \n",
       "2                2.6  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply pre-rules to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Line char for replacement in text\n",
    "NL = 'xxnl'\n",
    "defaults.text_spec_tok.append(NL) #add a New Line special char\n",
    "\n",
    "def sub_nl(t:str) -> str:\n",
    "    \"Replaces \\n by xxnl\"\n",
    "    return t.replace(\"\\r\\n\",\"\\n\").replace(\"\\n\",NL+\" \")\n",
    "\n",
    "# def sub_br(t:str) -> str:\n",
    "#     \"Replaces the <br /> by \\n\"\n",
    "#     re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "#     return re_br.sub(\"\\n\", t)\n",
    "\n",
    "def spec_add_spaces(t:str) -> str:\n",
    "    \"Add spaces between special characters\"\n",
    "    return re.sub(r'([/#?!@,])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t:str) -> str:\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t:str) -> str:\n",
    "    \"Replace repetitions at the character level\"\n",
    "    def _replace_rep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "    \n",
    "def replace_wrep(t:str) -> str:\n",
    "    \"Replace word repetitions\"\n",
    "    def _replace_wrep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def deal_caps(t:str) -> str:\n",
    "    \"Replace words in all caps\"\n",
    "    res = []\n",
    "    for s in re.findall(r'\\w+|\\W+', t):\n",
    "        res += ([f' {TK_UP} ',s.lower()] if (s.isupper() and (len(s)>2)) else [s.lower()])\n",
    "    return ''.join(res)\n",
    "\n",
    "def fixup(x:str) -> str:\n",
    "    \"List of replacements from html strings\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "default_rules = [fixup, replace_rep, replace_wrep, deal_caps, spec_add_spaces, \n",
    "                 rm_useless_spaces, sub_nl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Rules:\n",
      " ['fixup', 'replace_rep', 'replace_wrep', 'deal_caps', 'spec_add_spaces', 'rm_useless_spaces', 'sub_nl'] \n",
      "\n",
      "\n",
      "<function fixup at 0x7f76b32b62f0>\n",
      "<function replace_rep at 0x7f76b32b6158>\n",
      "<function replace_wrep at 0x7f76b32b61e0>\n",
      "<function deal_caps at 0x7f76b32b6268>\n"
     ]
    }
   ],
   "source": [
    "## apply the rules\n",
    "raw_text = all_texts_df.loc[:,'text']\n",
    "\n",
    "print(\"Default Rules:\\n\",[x.__name__ for x in default_rules],\"\\n\\n\")\n",
    "\n",
    "for rule in default_rules:\n",
    "    print(rule)\n",
    "    raw_text = raw_text.apply(lambda x: rule(str(x)))\n",
    "    \n",
    "all_texts_df['new_text'] = 'xxbos ' + raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_df['new_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the imbalanced data to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of positive samples:', (all_texts_df.is_humor == 1).sum())\n",
    "print('Number of negative samples:',  (all_texts_df.is_humor == 0).sum())\n",
    "print('Total samples:', len(all_texts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_seed = 20190313\n",
    "np.random.seed(rnd_seed)\n",
    "\n",
    "idx = np.random.permutation(len(all_texts_df))\n",
    "test_cut = int(0.15 * len(idx))\n",
    "valid_cut = int(0.15 * len(idx-test_cut))\n",
    "\n",
    "df_train_all = all_texts_df.iloc[idx[:-(valid_cut+test_cut)],:]\n",
    "df_valid     = all_texts_df.iloc[idx[-(valid_cut+test_cut):-test_cut],:]\n",
    "df_test      = all_texts_df.iloc[idx[-test_cut:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test prevalence(n = %d):'%len(df_test),df_test.is_humor.sum()/ len(df_test))\n",
    "print('Valid prevalence(n = %d):'%len(df_valid),df_valid.is_humor.sum()/ len(df_valid))\n",
    "print('Train all prevalence(n = %d):'%len(df_train_all), df_train_all.is_humor.sum()/ len(df_train_all))\n",
    "print('all samples (n = %d)'%len(all_texts_df))\n",
    "assert len(all_texts_df) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## oversample the less-frequent occuring cases\n",
    "# split the training data into positive and negative\n",
    "rows_pos = df_train_all.is_humor == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "df_train_pos.shape,df_train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resample_pos = df_train_pos.sample(n=len(df_train_neg),replace=True,\n",
    "                                      axis=0,random_state=rnd_seed).reset_index(drop=True)\n",
    "df_train = pd.concat([df_resample_pos,df_train_neg],axis=0) #randomized again in DataBunch?\n",
    "print('Train prevalence (n = %d):'%len(df_train), df_train.is_humor.sum()/ len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sp tokenizer from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = './all_tweets_es_0509'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## itos from m.vocab file: just read directly and populate the dictionary\n",
    "itos = [] #{}\n",
    "with open(f'{model_prefix}.vocab','r') as f:\n",
    "    for line_num,line in enumerate(f):\n",
    "#         itos[line_num] = line.split(\"\\t\")[0]\n",
    "        itos.append(line.split(\"\\t\")[0])\n",
    "        \n",
    "class SPTokenizer(BaseTokenizer):\n",
    "    \"Wrapper around a SentncePiece tokenizer to make it a `BaseTokenizer`.\"\n",
    "    def __init__(self, model_prefix:str):\n",
    "        self.tok = spm.SentencePieceProcessor()\n",
    "        self.tok.load(f'{model_prefix}.model')\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.tok.EncodeAsIds(t)  ## tokenize + numericalize. We have them broken into two parts,just return tokens\n",
    "        return self.tok.EncodeAsPieces(t)\n",
    "        \n",
    "class CustomTokenizer():\n",
    "    '''Wrapper for SentencePiece toeknizer to fit into Fast.ai V1'''\n",
    "    def __init__(self,tok_func:Callable,model_prefix:str, pre_rules:ListRules=None):\n",
    "        self.tok_func,self.model_prefix = tok_func,model_prefix\n",
    "        self.pre_rules  = ifnone(pre_rules,  defaults.text_pre_rules )\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        res = f'Tokenizer {self.tok_func.__name__} using `{self.model_prefix}` model with the following rules:\\n'\n",
    "        for rule in self.pre_rules: res += f' - {rule.__name__}\\n'\n",
    "        return res        \n",
    "\n",
    "    def process_text(self, t:str,tok:BaseTokenizer) -> List[str]:\n",
    "        \"Processe one text `t` with tokenizer `tok`.\"\n",
    "        for rule in self.pre_rules: t = rule(t)  \n",
    "        toks = tok.tokenizer(t)\n",
    "    \n",
    "        return toks \n",
    "    \n",
    "    def _process_all_1(self,texts:Collection[str]) -> List[List[str]]:\n",
    "        'Process a list of `texts` in one process'\n",
    "        tok = self.tok_func(self.model_prefix)\n",
    "        return [self.process_text(t,tok) for t in texts]\n",
    "                                                                     \n",
    "    def process_all(self, texts:Collection[str]) -> List[List[str]]: \n",
    "        \"Process a list of `texts`.\"                                 \n",
    "        return self._process_all_1(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycust_tok = CustomTokenizer(SPTokenizer,model_prefix,pre_rules=default_rules)\n",
    "sp_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextClasDataBunch.from_df(PATH,df_train,df_valid,df_test,\n",
    "                               tokenizer=mycust_tok, vocab=sp_vocab,\n",
    "                               text_cols='new_text', label_cols='is_humor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(10)  #less xxunk, but still a fair amount..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check `xxunk` fraction on humor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_xxunk = pd.Series([sum(y==0)/len(y) for y in [x.data for x in data.train_dl.x]])\n",
    "pct_xxunk[pct_xxunk>0].shape, pct_xxunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "498/20704."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([sum(y==0)/len(y) for y in [x.data for x in data.train_dl.x]]).plot()\n",
    "_ = plt.title('Pct UNK in each tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfmer_clas_config.copy()\n",
    "config['n_layers'] = 8\n",
    "config['ctx_len'] = 128\n",
    "config['d_model'] = 512\n",
    "config['d_inner'] = 2048\n",
    "config['mask'] = True  \n",
    "\n",
    "learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5,pretrained=False,\n",
    "                               config=config)\n",
    "learn.load_encoder('twitter_es_enc_Tfm_0516')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace with attention head for classifier?\n",
    "learn.freeze()\n",
    "learn.fit_one_cycle(20, 1e-2, moms=(0.8,0.7),\n",
    "                   callbacks=[SaveModelCallback(learn,every='improvement',mode='max',monitor='accuracy',name='best_acc_model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Tfm_trained_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = learn.load('rnn_trained_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(20,slice(1e-3/(2.6**2),1e-3),moms=(0.7,0.4), wd=0.10,\n",
    "                   callbacks=[SaveModelCallback(learn,every='improvement',mode='max',monitor='accuracy',name='best_acc_model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "\n",
    "learn.fit_one_cycle(20,slice(1e-3/(2.6**3),1e-3),moms=(0.7,0.4), wd=0.10,\n",
    "                   callbacks=[SaveModelCallback(learn,every='improvement',mode='max',monitor='accuracy',name='best_acc_model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(20,slice(1e-4/(2.6**4),1e-3),moms=(0.6,0.4), pct_start=0.10\n",
    "                   callbacks=[SaveModelCallback(learn,every='improvement',mode='max',monitor='accuracy',name='best_acc_model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_t,y_t,losses_t = learn.get_preds(DatasetType.Train,with_loss=True)\n",
    "interp_t = ClassificationInterpretation(learn, preds_t, y_t, losses_t)\n",
    "interp_t.plot_confusion_matrix()\n",
    "\n",
    "preds,y,losses = learn.get_preds(with_loss=True)\n",
    "interp = ClassificationInterpretation(learn, preds, y, losses)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models.awd_lstm import TextClassificationInterpretation\n",
    "from matplotlib.pyplot import cm\n",
    "txt_ci = TextClassificationInterpretation.from_learner(learn)\n",
    "(_,idxs) = interp.top_losses(5)\n",
    "for idx in to_np(idxs):\n",
    "    print(\"-\"*10)\n",
    "    txt_ci.show_intrinsic_attention(df_train.iloc[idx,1],cmap=cm.Blues) #textify breaks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"haha_20190516_tweet_vocab_qrnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save predictions for use in Ensemble method (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(to_np(preds)).to_csv('rnn_sent_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## fastai \"test\" has no labels.  It is a true test, not a whitholding set!!  We need a second valid set?\n",
    "## move the df_test into the \"valid\" position so we can run inference and get preds on randomized vals\n",
    "data_t = TextClasDataBunch.from_df(PATH,df_train,df_test,\n",
    "                               tokenizer=mycust_tok, vocab=sp_vocab,\n",
    "                               text_cols='new_text', label_cols='is_humor')\n",
    "learn.data = data_t\n",
    "t_preds,t_y,t_losses = learn.get_preds(with_loss=True,ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(to_np(t_preds)).to_csv('rnn_sent_t_preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
