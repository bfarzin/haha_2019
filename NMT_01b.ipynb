{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMT (seq2seq) in fastai v1\n",
    "\n",
    "Start with this:<br>\n",
    "https://gist.github.com/ohmeow/fe91aed6267cd779946ab9f10eccdab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATA_PATH = Path('./data/es-en')\n",
    "\n",
    "BASE = 'europarl-v7.es-en'\n",
    "en_file = DATA_PATH/f'{BASE}.en'\n",
    "es_file = DATA_PATH/f'{BASE}.es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split, build DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    x_max_len = max([len(s[0]) for s in samples])\n",
    "    y_max_len = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    return x_res, y_res\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for classification.  Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/seq2seq/')\n",
    "bs = 64\n",
    "\n",
    "## load the saved data.\n",
    "data = load_data(PATH, \"full_es_en_data_spacyTok.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 255]), torch.Size([64, 252]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(data.train_dl))\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 255])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 252])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541, 58838)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), len(data.label_list.train.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'the',\n",
       "  ',',\n",
       "  '.',\n",
       "  'of',\n",
       "  'to',\n",
       "  'and',\n",
       "  'in',\n",
       "  'that',\n",
       "  'a',\n",
       "  'is',\n",
       "  'we'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), data.label_list.train.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model for Seq2Seq\n",
    "\n",
    "Big help from this link from the old course + looking at the `Transformer` code and adapting <br>\n",
    "https://github.com/kheyer/ML-DL-Projects/blob/master/Seq2Seq%20Transformer/Transformer.ipynb\n",
    "\n",
    "and here:<br>\n",
    "https://nbviewer.jupyter.org/github/fastai/fastai/blob/6ba17b21599a6fc441794ffd130bc31b5333b4a0/courses/dl2/translate.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m_MultiHeadAttention(nn.Module):\n",
    "    \"MutiHeadAttention.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
    "                 scale:bool=True):\n",
    "        super().__init__()\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
    "        self.att_q = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_k = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_v = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
    "        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None, **kwargs):\n",
    "        \"attn -> Linear -> drop -> merge -> LN\"\n",
    "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask, **kwargs))))\n",
    "    \n",
    "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
    "        bs,x_len = q.size(0),q.size(1) # bs x bptt x d_model\n",
    "        wq,wk,wv = self.att_q(q), self.att_k(k), self.att_v(v)\n",
    "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
    "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
    "        attn_score = torch.matmul(wq, wk)\n",
    "        if self.scale: attn_score.div_(self.d_head ** 0.5)\n",
    "        if mask is not None: \n",
    "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
    "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
    "        attn_vec = torch.matmul(attn_prob, wv)\n",
    "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, x_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_activ_func = {Activation.ReLU:nn.ReLU(inplace=True), Activation.GeLU:GeLU(), Activation.Swish: Swish}\n",
    "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., act:Activation=Activation.ReLU, double_drop:bool=True):\n",
    "    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n",
    "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
    "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
    "\n",
    "class m_EncoderLayer(nn.Module):\n",
    "    \"Basic block of a Transformer model.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=m_MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.mhra = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x:Tensor, mask:Tensor=None, **kwargs): return self.ff(self.mhra(x, x, x, mask=mask, **kwargs))\n",
    "\n",
    "class m_DecoderLayer(nn.Module):\n",
    "    \"Decoder block for seq2seq. Self and target attention combined.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=m_MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.mhra_s    = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.mhra_targ = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "        \n",
    "    def forward(self, x:Tensor, enc_out:Tensor, src_mask:Tensor=None, targ_mask:Tensor=None, **kwargs): \n",
    "        x = self.mhra_s(x,x,x, mask=targ_mask, **kwargs)\n",
    "        return self.ff(self.mhra_targ(x, enc_out, enc_out, mask=src_mask, **kwargs))\n",
    "    \n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n",
    "    def __init__(self, vocab_sz:int, tgt_vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, \n",
    "                 d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=True, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=m_MultiHeadAttention,\n",
    "                 learned_pos_enc:bool=True, mask:bool=True):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.encoder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_emb = nn.Dropout(embed_p)\n",
    "\n",
    "        self.enc_layers = nn.ModuleList([m_EncoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls) for k in range(n_layers)])\n",
    "\n",
    "        self.decoder = nn.Embedding(tgt_vocab_sz, d_model)\n",
    "        self.pos_dec = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_dec = nn.Dropout(embed_p)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([m_DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls) for k in range(n_layers)])\n",
    "        \n",
    "        self.tgt_word_prj = nn.Linear(d_model, tgt_vocab_sz, bias=False)\n",
    "        nn.init.xavier_normal_(self.tgt_word_prj.weight)\n",
    "        self.x_logit_scale = (d_model ** -0.5)\n",
    "        \n",
    "    def reset(self):pass\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        bs, x_len = x.size()\n",
    "        bs, y_len = y.size()\n",
    "        pos = torch.arange(0, x_len, device=x.device, dtype=x.dtype)\n",
    "        inp = self.drop_emb(self.encoder(x) + self.pos_enc(pos)[None]) #.mul_(self.d_model ** 0.5)\n",
    "        pos_y = torch.arange(0, y_len, device=x.device, dtype=x.dtype)\n",
    "        targ = self.drop_dec(self.decoder(y) + self.pos_dec(pos_y)[None]) #.mul_(self.d_model ** 0.5)\n",
    "\n",
    "        ## masking/padding is not yet right here.  Needs to be fixed to mask the pad IDs\n",
    "        src_mask = (x==1).byte()[:,None,None,:] #[64,5,155,155]\n",
    "        #mask == trg_mask (but trg_mask also masks out all xxpad ids [id==1]  add that here)\n",
    "        nopeak_mask = torch.triu(x.new_ones(y_len, y_len), diagonal=1).byte() if self.mask else None\n",
    "        targ_mask = (y==1).byte()[:,None,:,None] * nopeak_mask\n",
    "        \n",
    "        for layer in self.enc_layers: inp  = layer(inp, mask=src_mask)\n",
    "        for layer in self.dec_layers: targ = layer(targ, inp, src_mask=src_mask, targ_mask=targ_mask)\n",
    "        decoded = self.tgt_word_prj(targ) * self.x_logit_scale\n",
    "\n",
    "        return [decoded, decoded, decoded] #for RNN trainer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfm_seq2seq = Seq2SeqTransformer(vocab_sz=len(data.label_list.train.x.vocab.itos),\n",
    "                       tgt_vocab_sz=len(data.label_list.train.y.vocab.itos),\n",
    "                       ctx_len=256, n_layers=6, n_heads=10, d_model=300, d_head=64, d_inner=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_seq2seq = Seq2SeqTransformer(vocab_sz=len(data.label_list.train.x.vocab.itos),\n",
    "                       tgt_vocab_sz=len(data.label_list.train.y.vocab.itos),\n",
    "                       ctx_len=256, n_layers=3, n_heads=5, d_model=300, d_head=None, d_inner=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transformer(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 0., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n",
    "    elif classname.find('LayerNorm') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 1., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tfm_seq2seq.apply(init_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    '''\n",
    "    Loss should be different:\n",
    "    * Remove padding difference of input/output sentence length? (already done in dataset: makes square)\n",
    "    * Trigger masing with xxbos/xxeos codes?\n",
    "    '''\n",
    "    \"Loss blanking out anything after xxeos\"\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = LanguageLearner(data, tfm_seq2seq, **{'alpha':0,'beta':0}, callbacks=[AppendBatchTargs()], loss_func=CrossEntropyFlat())\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'56,765,388'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
    "f'{total_params:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 16  ## 64 fails to load.  Prob. too big embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 27:24:01 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.198410</th>\n",
       "    <th>0.201557</th>\n",
       "    <th>1:05:43</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.194250</th>\n",
       "    <th>0.213202</th>\n",
       "    <th>1:06:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.202427</th>\n",
       "    <th>0.209386</th>\n",
       "    <th>1:06:21</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.168224</th>\n",
       "    <th>0.178699</th>\n",
       "    <th>1:05:54</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.193883</th>\n",
       "    <th>0.208172</th>\n",
       "    <th>1:05:59</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.197498</th>\n",
       "    <th>0.209220</th>\n",
       "    <th>1:05:51</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.164671</th>\n",
       "    <th>0.185437</th>\n",
       "    <th>1:05:48</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.186331</th>\n",
       "    <th>0.188318</th>\n",
       "    <th>1:05:28</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.195042</th>\n",
       "    <th>0.207437</th>\n",
       "    <th>1:06:03</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.189739</th>\n",
       "    <th>0.206231</th>\n",
       "    <th>1:06:05</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.195218</th>\n",
       "    <th>0.202982</th>\n",
       "    <th>1:06:01</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.201661</th>\n",
       "    <th>0.202568</th>\n",
       "    <th>1:05:59</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.195093</th>\n",
       "    <th>0.209339</th>\n",
       "    <th>1:05:17</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.191689</th>\n",
       "    <th>0.199548</th>\n",
       "    <th>1:05:50</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.198197</th>\n",
       "    <th>0.201567</th>\n",
       "    <th>1:05:18</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.189119</th>\n",
       "    <th>0.187881</th>\n",
       "    <th>1:05:56</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.179265</th>\n",
       "    <th>0.197492</th>\n",
       "    <th>1:05:58</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.193502</th>\n",
       "    <th>0.203007</th>\n",
       "    <th>1:05:50</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.177614</th>\n",
       "    <th>0.200925</th>\n",
       "    <th>1:05:38</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.187235</th>\n",
       "    <th>0.200598</th>\n",
       "    <th>1:05:30</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.179217</th>\n",
       "    <th>0.198339</th>\n",
       "    <th>1:05:22</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>21</th>\n",
       "    <th>0.193867</th>\n",
       "    <th>0.198416</th>\n",
       "    <th>1:05:29</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>22</th>\n",
       "    <th>0.172275</th>\n",
       "    <th>0.196243</th>\n",
       "    <th>1:05:27</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>23</th>\n",
       "    <th>0.166452</th>\n",
       "    <th>0.176993</th>\n",
       "    <th>1:05:08</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>24</th>\n",
       "    <th>0.172091</th>\n",
       "    <th>0.182035</th>\n",
       "    <th>1:05:54</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## fit one cycle is just too darn agressive for Transformer. Why?\n",
    "## loss going to nearly zero means we are peaking. How?\n",
    "learn.fit(25, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,     5,    11,     5,    35,    23,    83,   621,    19,   209,\n",
       "          486,    10,   724,    10,   820,    10,   952,    10,  1210,    10,\n",
       "         1414,    10,  1657,    10,  1322,    10,  1471,    10,   985,    10,\n",
       "         1880,    10,  2167,    10,  2270,    10,  2091,    10,   909,    10,\n",
       "         1803,    10,  2664,    10,  2780,    10,  1192,    10,  2596,    10,\n",
       "         4019,    10,  4283,    10,  3091,    10,  3651,    10,  4856,    10,\n",
       "         4271,    10,  4792,    10,  4964,    10,  3745,    10,  5538,    10,\n",
       "         5664,    10,  4074,    10,  5296,    10,  5858,    10,  6064,    10,\n",
       "         6978,    10,  4424,    10,  6428,    10,  6963,    10,  6632,    10,\n",
       "         7383,    10,  8393,    10,  2530,    10,  5315,    10,  4053,    10,\n",
       "         7715,    10,  2282,    10,  7931,    10, 10684,    10,  5890,    10,\n",
       "         8345,    10,  2640,    10,  7729,    10,  6045,    10,  7007,    10,\n",
       "         8048,    10,  3974,    10,  5856,    10,  6467,    10,  6407,    10,\n",
       "         1988,    10, 15977,    10, 13748,    10,  7522,    10, 12517,    10,\n",
       "        10790,    10, 15227,    10, 10378,    10, 12482,    10,  8856,    10,\n",
       "        12880,    10, 11224,    10,  8460,    10, 10709,    10,  9200,    10,\n",
       "         6896,    10, 17382,    10,  9908,    10,  4629,    10, 14021,    10,\n",
       "         9174,    10,  9877,    10, 19823,    10,     1,    10,  7877,    10,\n",
       "        11180,    10, 14171,    10,  6357,    10, 10674,    10,     9,    10,\n",
       "         8398,    10,     9,    10, 10778,    10,     9,    10,  5899,    10,\n",
       "         8130,    10,     5,    10,  8630,    10,  6686,    10,  6589,    10,\n",
       "         6171,    10,  9914,    10,  7381,    10,     1,    10,  8903,    10,\n",
       "           14,    10,     1,    10,  5775,    10,     1,    10,  8339,    10,\n",
       "          772,    10,    13,    10,  8805,    10,     1,    10,     9,    10,\n",
       "            9,    10,     1,    10,     1,    10,  9515,    10,  9336,     2,\n",
       "            1,    10], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(learn.data.valid_dl))\n",
    "preds = learn.model(x,y)\n",
    "preds[0][0,:].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_itos = data.label_list.train.x.vocab.itos\n",
    "y_itos = data.label_list.train.y.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj the xxmaj commission can not accept amendments 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 , 239 , 240 ,\n",
      "xxbos xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 ,\n",
      "xxbos xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , obsesión , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , conseguirán , pagamos , potente , 131 , 133 , habilidades , polvo , stalin , 137 , 138 , tocar , 150 , 151 , 152 , financian , 154 , , basura , 160 , 162 , constantes , incoherencia , de , financieramente , de , 170 , de , lento , neumáticos , xxmaj , guardan , interpretaciones , ludford , migrantes , actuemos , proporcional , , tapete , en , , dominante , , grasas , ! , que , repartir , , de , de , , , restringido , consumir xxbos ,\n",
      "\n",
      "xxbos xxmaj the xxmaj commission can accept the following amendments : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 and 164 to 209 .\n",
      "xxbos xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 y 164 a 209 .\n",
      "xxbos xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , obsesión , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , descentralizada , 102 , 103 , eventos , 106 , 107 , 108 , 111 , 112 , jugando , 115 , aprueban , de , 120 , george , abogo , montaña , obligan , 125 , ) , xxbos , 137 , comparativas , 140 , . , 142 , xxbos , 144 , , propiamente , 147 , 148 , enteras , 150 , 151 , 152 , financian , , , , 157 , violando y necesiten a actualizado .\n",
      "\n",
      "xxbos xxmaj the next item is the oral question to the xxmaj commission ( xxup b5 - 0206 / 2000 ) by xxmaj mr xxmaj lannoye , xxmaj mrs xxmaj auroi , xxmaj mr xxmaj bouwman , xxmaj mr xxmaj bowe , xxmaj mrs xxmaj cerdeira xxmaj morterero , xxmaj mrs xxmaj corbey , xxmaj mr xxmaj costa xxmaj paolo , xxmaj mr xxmaj deprez , xxmaj mr xxmaj desama , xxmaj mrs xxmaj gonzález xxmaj álvarez , xxmaj mrs xxmaj guy - xxmaj quint , xxmaj mr xxmaj izquierdo xxmaj collado , xxmaj mr xxmaj jonckheer , xxmaj mrs xxmaj korhola , xxmaj mr xxmaj kreissl - xxmaj dörfler , xxmaj mrs xxmaj lienemann , xxmaj mrs xxmaj lucas , xxmaj mrs mckenna , xxmaj mrs xxmaj maes , xxmaj mr xxmaj martínez xxmaj martínez , xxmaj mr xxmaj papayannakis , xxmaj mrs xxmaj patrie , xxmaj mr xxmaj arvidsson , xxmaj mr xxmaj puerta , xxmaj mr xxmaj ries , xxmaj mr xxmaj rod , xxmaj mr de xxmaj roo , xxmaj mrs xxmaj sandbæk , xxmaj mrs xxmaj schroedter , xxmaj mrs xxmaj sornosa xxmaj martínez , xxmaj mr xxmaj staes , xxmaj mr xxmaj sterckx , xxmaj mrs xxmaj terrón i xxmaj cusí , xxmaj mrs xxmaj van xxmaj brempt , xxmaj mr xxmaj vander xxmaj taelen , xxmaj mrs xxmaj van xxmaj lancker and xxmaj mr xxmaj ducarme , regarding night flights and noise pollution around airports .\n",
      "xxbos xxmaj de conformidad con el orden del orden del día se procede a la pregunta oral formulada a la xxmaj comisión por los diputados xxmaj lannoye , xxmaj auroi , xxmaj bouwman , xxmaj bowe , xxmaj cerdeira xxmaj morterero , xxmaj corbey , xxmaj costa xxmaj paolo , xxmaj deprez , xxmaj desama , xxmaj gonzález xxmaj álvarez , xxmaj guy - xxmaj quint , xxmaj izquierdo xxmaj collado , xxmaj jonckheer , xxmaj korhola , xxmaj kreissl - xxmaj dörfler , xxmaj lienemann , xxmaj lucas , mckenna , xxmaj maes , xxmaj martínez xxmaj martínez , xxmaj papayannakis , xxmaj patrie , xxmaj arvidsson , xxmaj puerta , xxmaj ries , xxmaj rod , de xxmaj roo , xxmaj sandbæk , xxmaj schroedter , xxmaj sornosa xxmaj martínez , xxmaj staes , xxmaj sterckx , xxmaj terrón i xxmaj cusí , xxmaj van xxmaj brempt , xxmaj vander xxmaj taelen , xxmaj van xxmaj lancker , xxmaj ducarme , sobre los vuelos nocturnos y las molestias sonoras en las cercanías de los aeropuertos ( xxup b5 - 0206 / 2000 ) .\n",
      "xxbos xxmaj de conformidad con el orden del orden del día se procede a la pregunta oral formulada a la xxmaj comisión por los diputados xxmaj lannoye , xxmaj auroi , xxmaj bouwman , xxmaj gobernantes , xxmaj xxmaj , , xxmaj corbey , xxmaj costa xxmaj paolo , xxmaj deprez , xxmaj xxmaj , xxmaj gonzález xxmaj álvarez , xxmaj guy - xxmaj la , xxmaj izquierdo xxmaj collado , xxmaj jonckheer , xxmaj korhola , xxmaj kreissl - xxmaj dörfler , xxmaj lienemann , xxmaj lucas , mckenna , xxmaj maes , xxmaj polvo xxmaj polvo , xxmaj papayannakis , xxmaj patrie , xxmaj . , xxmaj puerta , xxmaj ries , xxmaj concebir , de xxmaj roo , xxmaj vigilantes , xxmaj schroedter , xxmaj plátano xxmaj polvo , xxmaj staes , xxmaj sterckx , xxmaj terrón i xxmaj cusí , xxmaj van xxmaj brempt , xxmaj xxbos xxmaj taelen , xxmaj van xxmaj lancker , xxmaj xxbos , sobre los vuelos nocturnos y las molestias necesitará en las de los aeropuertos ( xxup b5 - / 2000 ) . de de\n",
      "\n",
      "xxbos - xxup a5 - 0212 / 2004 by xxmaj mr xxmaj mulder , on the discharge to the xxmaj european xxmaj agency for xxmaj reconstruction for the financial year 2002 ( xxup c5 - 0632 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for xxmaj safety and xxmaj health at xxmaj work for the financial year 2002 ( xxup c5 - 0636 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj environment xxmaj agency for the financial year 2002 ( xxup c5 - 0635 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for the xxmaj evaluation of xxmaj medicinal xxmaj products for the financial year 2002 ( xxup c5 - 0638 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj translation xxmaj centre for the xxmaj bodies of the xxmaj european xxmaj union for the financial year 2002 ( xxup c5 - 0637 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj centre for the xxmaj development of xxmaj vocational xxmaj training for the financial year 2002 ( xxup c5 - 0630 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to xxmaj eurojust\n",
      "xxbos xxmaj fundación xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - 0631 / 2003 – 2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj toxicomanías ( xxup c5 - 0634 / 2003 – 2003 / xxup xxunk ) ) ; 11 .\n",
      "xxbos xxmaj fundación xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - de / 2003 – 2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj toxicomanías ( xxup c5 - . / 2003 – 2003 / xxup xxunk ) ) ; 11 . de\n",
      "\n",
      "xxbos xxmaj oral question ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) by xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj xxunk xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj antonia xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk and xxmaj lennart xxmaj sacrédeus - xxmaj media concentration and pluralism\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) de xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj clemente xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj xxunk xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk y xxmaj lennart xxmaj sacrédeus - xxmaj concentración y pluralismo de los medios de comunicación\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - de / 02 ) de xxmaj xxunk xxmaj xxbos , xxmaj xxmaj contamina , xxmaj ha xxmaj almeida xxmaj garrett , xxmaj guido xxmaj xxbos , xxmaj juan xxmaj josé xxmaj bayona de xxmaj , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj xxbos xxmaj la , xxmaj –la xxmaj collins , xxmaj preparada xxmaj cornillet , xxmaj interesada xxmaj que , xxmaj admisible xxmaj crowley , xxmaj xxbos xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj xxup xxunk xxmaj deprez , xxmaj tecnológicos xxmaj dimitrakopoulos , xxmaj actuemos xxmaj fatuzzo , xxmaj xxmaj deudas xxmaj ejecutiva , xxmaj xxunk xxmaj estimación , xxmaj negociando xxmaj el , xxmaj xxmaj hatzidakis , xxmaj xxmaj 76 , xxmaj el xxmaj que , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj por xxmaj xxunk , xxmaj la xxmaj definidas , xxmaj juan xxmaj ojeda xxmaj préstamos , xxmaj observo la xxmaj neachtain , xxmaj ciudadana xxmaj oreja xxmaj , xxmaj josé xxmaj que xxmaj el , xxmaj grano xxmaj xxunk , xxmaj habilidades xxmaj xxunk xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj basura xxmaj brutales , xxmaj xxbos xxmaj pronk y xxmaj xxmaj sacrédeus - xxmaj concentración y pluralismo de los medios de comunicación , de xxbos de de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(5):\n",
    "    print(' '.join([x_itos[o] for o in x[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in y[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in preds[0][i,:].argmax(dim=1) if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to separate encoder/decoder parts.\n",
    "### Tranaslation will be:\n",
    "# * Set state from src sentence in encoder (torch.no_grad() to keep state?)\n",
    "# * start with xxbos token\n",
    "# * proceed through each step with next word (example below)\n",
    "# * OR:  beam_search() to get best set of next words up to end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encoder(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decoder(Variable(ys), memory, src_mask, Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
    "        prob = F.softmax(model.out(out[:, -1]))\n",
    "        #_, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = torch.multinomial(prob, 1)\n",
    "        next_word = next_word.data[0][0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos 2 , 4 , 6 , 7 , 10 , 11 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 25 , 27 , 28 , 30 , 33 , 35 , 36 , 37 , 38 , 41 , 42 , 43 , 44 , 45 , 49 , 50 , 56 , 57 , 59 , 60 , 61 , 64 , 69 , 72 , 75 , 77 , 78 , 79 , 82 , 83 , 84 , 85 , 92 , 98 , 100 , 104 , 107 , 108 , 109 , 112 , 113 , 115 , 118 , 119 , 121 , 122 , 123 , 124 , 126 , 127 , 128 , 131 , 132 , 133 , 134 , 135 , 140 , 145 , 147 , 148 , 149 , 153 , 155 , 156 , 157 , 158 , 163 , 166 , 167 , 168 , 178 , 179 , 180 , 182 , 183 , 186 , 187 , 188 , 191 , 197 , 201 , 202 , 203 , 205 , 206 , 208 , 209 , 210 , 211 , 212 , 213 , 214 and 215 .\n"
     ]
    }
   ],
   "source": [
    "ys = greedy_decode(m, src[10].unsqueeze(0), src_mask[10], enlen_90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Embedding(35541, 300)\n",
       "  (pos_enc): Embedding(256, 300)\n",
       "  (drop_emb): Dropout(p=0.0)\n",
       "  (enc_layers): ModuleList(\n",
       "    (0): m_EncoderLayer(\n",
       "      (mhra): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): m_EncoderLayer(\n",
       "      (mhra): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): m_EncoderLayer(\n",
       "      (mhra): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Embedding(58838, 300)\n",
       "  (pos_dec): Embedding(256, 300)\n",
       "  (drop_dec): Dropout(p=0.0)\n",
       "  (dec_layers): ModuleList(\n",
       "    (0): m_DecoderLayer(\n",
       "      (mhra_s): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mhra_targ): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): m_DecoderLayer(\n",
       "      (mhra_s): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mhra_targ): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): m_DecoderLayer(\n",
       "      (mhra_s): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mhra_targ): m_MultiHeadAttention(\n",
       "        (att_q): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_k): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (att_v): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (drop_att): Dropout(p=0.0)\n",
       "        (drop_res): Dropout(p=0.0)\n",
       "        (ln): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff): SequentialEx(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (1): ReLU(inplace)\n",
       "          (2): Dropout(p=0.0)\n",
       "          (3): Linear(in_features=2048, out_features=300, bias=True)\n",
       "          (4): Dropout(p=0.0)\n",
       "          (5): MergeLayer()\n",
       "          (6): LayerNorm(torch.Size([300]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tgt_word_prj): Linear(in_features=300, out_features=58838, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can we use this encoder as a LM for english??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
