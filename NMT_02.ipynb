{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMT (seq2seq) in fastai v1\n",
    "\n",
    "Start with this:<br>\n",
    "https://gist.github.com/ohmeow/fe91aed6267cd779946ab9f10eccdab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATA_PATH = Path('./data/es-en')\n",
    "\n",
    "BASE = 'europarl-v7.es-en'\n",
    "en_file = DATA_PATH/f'{BASE}.en'\n",
    "es_file = DATA_PATH/f'{BASE}.es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split, build DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    x_max_len = max([len(s[0]) for s in samples])\n",
    "    y_max_len = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    return x_res, y_res\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for classification.  Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/seq2seq/')\n",
    "bs = 64\n",
    "\n",
    "## load the saved data.\n",
    "data = load_data(PATH, \"full_es_en_data_spacyTok.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 255]), torch.Size([64, 252]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(data.train_dl))\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 255])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 252])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541, 58838)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), len(data.label_list.train.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'the',\n",
       "  ',',\n",
       "  '.',\n",
       "  'of',\n",
       "  'to',\n",
       "  'and',\n",
       "  'in',\n",
       "  'that',\n",
       "  'a',\n",
       "  'is',\n",
       "  'we'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), data.label_list.train.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model for Seq2Seq\n",
    "\n",
    "Big help from this link from the old course + looking at the `Transformer` code and adapting <br>\n",
    "https://github.com/kheyer/ML-DL-Projects/blob/master/Seq2Seq%20Transformer/Transformer.ipynb\n",
    "\n",
    "and here:<br>\n",
    "https://nbviewer.jupyter.org/github/fastai/fastai/blob/6ba17b21599a6fc441794ffd130bc31b5333b4a0/courses/dl2/translate.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m_MultiHeadAttention(nn.Module):\n",
    "    \"MutiHeadAttention.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
    "                 scale:bool=True):\n",
    "        super().__init__()\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
    "        self.att_q = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_k = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_v = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
    "        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None, **kwargs):\n",
    "        \"attn -> Linear -> drop -> merge -> LN\"\n",
    "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask, **kwargs))))\n",
    "    \n",
    "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
    "        bs,x_len = q.size(0),q.size(1) # bs x bptt x d_model\n",
    "        wq,wk,wv = self.att_q(q), self.att_k(k), self.att_v(v)\n",
    "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
    "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
    "        attn_score = torch.matmul(wq, wk)\n",
    "        if self.scale: attn_score.div_(self.d_head ** 0.5)\n",
    "        if mask is not None: \n",
    "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
    "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
    "        attn_vec = torch.matmul(attn_prob, wv)\n",
    "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, x_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_activ_func = {Activation.ReLU:nn.ReLU(inplace=True), Activation.GeLU:GeLU(), Activation.Swish: Swish}\n",
    "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., act:Activation=Activation.ReLU, double_drop:bool=True):\n",
    "    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n",
    "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
    "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
    "    \n",
    "class EncDecLayer(nn.Module):\n",
    "    \"Decoder block for seq2seq. Self and target attention combined.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=m_MultiHeadAttention, is_decode=False):\n",
    "        super().__init__()\n",
    "        self.is_decode = is_decode\n",
    "        self.mhra_s    = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        if self.is_decode:\n",
    "            self.mhra_targ = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "        \n",
    "    def forward(self, x:Tensor, enc_out:Tensor=None, src_mask:Tensor=None, mask:Tensor=None, **kwargs):\n",
    "        assert self.is_decode == (enc_out is not None), \"Calling Decode `forward()` with out init `is_decode`\"\n",
    "        x = self.mhra_s(x,x,x, mask=mask, **kwargs)\n",
    "        if self.is_decode: x = self.mhra_targ(x, enc_out, enc_out, mask=src_mask, **kwargs)\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n",
    "    def __init__(self, vocab_sz:int, tgt_vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, \n",
    "                 d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=True, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=m_MultiHeadAttention,\n",
    "                 learned_pos_enc:bool=True, mask:bool=True):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.encoder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_emb = nn.Dropout(embed_p)\n",
    "        self.enc_layers = nn.ModuleList([EncDecLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls, is_decode=False) for k in range(n_layers)])\n",
    "\n",
    "        self.decoder = nn.Embedding(tgt_vocab_sz, d_model)\n",
    "        self.pos_dec = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_dec = nn.Dropout(embed_p)\n",
    "        self.dec_layers = nn.ModuleList([EncDecLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls, is_decode=True) for k in range(n_layers)])\n",
    "        \n",
    "        self.tgt_word_prj = nn.Linear(d_model, tgt_vocab_sz, bias=False)\n",
    "        nn.init.xavier_normal_(self.tgt_word_prj.weight)\n",
    "        self.x_logit_scale = (d_model ** -0.5)\n",
    "        \n",
    "    def reset(self):pass\n",
    "\n",
    "    def encode_source(self, x):\n",
    "        \"encode layers to representation\"\n",
    "        bs, x_len = x.size()\n",
    "        pos = torch.arange(0, x_len, device=x.device, dtype=x.dtype)\n",
    "        inp = self.drop_emb(self.encoder(x) + self.pos_enc(pos)[None])\n",
    "        src_mask = (x==1).byte()[:,None,None,:] #[64,5,155,155]\n",
    "        for layer in self.enc_layers: inp  = layer(inp, mask=src_mask)            \n",
    "        return inp, src_mask\n",
    "\n",
    "    def decode_target(self, inp, src_mask, y):\n",
    "        \"decode layers\"\n",
    "        #mask == trg_mask (but trg_mask also masks out all xxpad ids [id==1]  add that here?)\n",
    "        bs, y_len = y.size()\n",
    "        pos_y = torch.arange(0, y_len, device=y.device, dtype=y.dtype)\n",
    "        targ = self.drop_dec(self.decoder(y) + self.pos_dec(pos_y)[None])\n",
    "        nopeak_mask = torch.triu(y.new_ones(y_len, y_len), diagonal=1).byte() if self.mask else None\n",
    "        targ_mask = (y==1).byte()[:,None,:,None] * nopeak_mask        \n",
    "        for layer in self.dec_layers: targ = layer(targ, inp, src_mask=src_mask, mask=targ_mask)\n",
    "        return targ\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        #encode layers\n",
    "        inp, src_mask = self.encode_source(x)\n",
    "        targ = self.decode_target(inp, src_mask, y)\n",
    "        decoded = self.tgt_word_prj(targ) * self.x_logit_scale\n",
    "        return [decoded, inp, targ]\n",
    "    \n",
    "def init_transformer(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 0., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n",
    "    elif classname.find('LayerNorm') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 1., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_seq2seq = Seq2SeqTransformer(vocab_sz=len(data.label_list.train.x.vocab.itos),\n",
    "                       tgt_vocab_sz=len(data.label_list.train.y.vocab.itos),\n",
    "                       ctx_len=256, n_layers=3, n_heads=5, d_model=300, d_head=None, d_inner=2048)\n",
    "_ = tfm_seq2seq.apply(init_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    \"Include the target in the training loop for Decoder mask\"\n",
    "    learn:Learner\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target[:,:-1]),\n",
    "                'last_target':last_target[:,1:]}        \n",
    "#     def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "#         return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLearner(RNNLearner):\n",
    "    \"Subclass of RNNLearner for predictions using Seq2Seq\"\n",
    "    \n",
    "    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None, sep:str=' ',\n",
    "                decoder=decode_spec_tokens):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        ## handle predictions for Seq2Seq\n",
    "        set_trace()\n",
    "        ds = self.data.single_dl.dataset\n",
    "        self.model.reset()\n",
    "        xb,yb = self.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(n_words): #progress_bar(range(n_words), leave=False):\n",
    "            res = self.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            #if len(new_idx) == 0: self.model[0].select_hidden([0])\n",
    "            if no_unk: res[self.data.vocab.stoi[UNK]] = 0.\n",
    "            if min_p is not None: res[res < min_p] = 0.\n",
    "            if temperature != 1.: res.pow_(1 / temperature)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        return text + sep + sep.join(decoder(self.data.vocab.textify(new_idx, sep=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Seq2SeqLearner(data, tfm_seq2seq, **{'alpha':0,'beta':0}, callbacks=[AppendBatchTargs()], loss_func=CrossEntropyFlat())\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'56,765,388'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
    "f'{total_params:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 16  ## 64 fails to load.  Prob. too big embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='49849', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-259ceaeb9151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fast_ai/fastai-fork/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fast_ai/fastai-fork/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_validate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 val_loss = validate(learn.model, learn.data.valid_dl, loss_func=learn.loss_func,\n\u001b[0;32m--> 106\u001b[0;31m                                        cb_handler=cb_handler, pbar=pbar)\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fast_ai/fastai-fork/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fast_ai/fastai-fork/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5e61ad1e6e25>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#encode layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_word_prj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_logit_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5e61ad1e6e25>\u001b[0m in \u001b[0;36mdecode_target\u001b[0;34m(self, inp, src_mask, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mnopeak_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtarg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnopeak_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b8fb528bf9a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, enc_out, src_mask, mask, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Calling Decode `forward()` with out init `is_decode`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmhra_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmhra_targ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d2fb5ebba56e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"attn -> Linear -> drop -> merge -> LN\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 158\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \"\"\"\n\u001b[1;32m   1650\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 1651\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(1, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,     5,    11,     5,    35,    23,    83,   621,    19,   209,\n",
       "          486,    10,   724,    10,   820,    10,   952,    10,  1210,    10,\n",
       "         1414,    10,  1657,    10,  1322,    10,  1471,    10,   985,    10,\n",
       "         1880,    10,  2167,    10,  2270,    10,  2091,    10,   909,    10,\n",
       "         1803,    10,  2664,    10,  2780,    10,  1192,    10,  2596,    10,\n",
       "         4019,    10,  4283,    10,  3091,    10,  3651,    10,  4856,    10,\n",
       "         4271,    10,  4792,    10,  4964,    10,  3745,    10,  5538,    10,\n",
       "         5664,    10,  4074,    10,  5296,    10,  5858,    10,  6064,    10,\n",
       "         6978,    10,  4424,    10,  6428,    10,  6963,    10,  6632,    10,\n",
       "         7383,    10,  8393,    10,  2530,    10,  5315,    10,  4053,    10,\n",
       "         7715,    10,  2282,    10,  7931,    10, 11149,    10,  5890,    10,\n",
       "         8345,    10,  2640,    10,  7729,    10,  6045,    10,  7007,    10,\n",
       "         8048,    10,  3974,    10,  5856,    10,  6467,    10,  6407,    10,\n",
       "         1988,    10,  8469,    10,  2606,    10,  7522,    10, 12517,    10,\n",
       "        10790,    10,  1099,    10,  3801,    10,   527,    10,  3507,    10,\n",
       "         6191,    10, 11224,    10,  1784,    10,    51,    10,   233,    10,\n",
       "         6896,    10,  6734,    10,  4560,    10,  4629,    10,  6051,    10,\n",
       "         9174,    10,  7398,    10,   156,    10,    66,    10,   107,    10,\n",
       "        11180,    10,  3143,    10,  1768,    10,  4410,    10,   653,    10,\n",
       "          429,    10,  1770,    10, 10778,    10,  3066,    10,  4824,    10,\n",
       "           19,    10,   164,    10,  8260,    10,  4871,    10,  4661,    10,\n",
       "           78,    10,  1420,    10,   786,    10,    33,    10,  1034,    10,\n",
       "         2126,    10,  1748,    10,  1719,    10,    66,    10,  3363,    10,\n",
       "         5314,    10,  1054,    10,  2241,    10,  2126,    10,   393,    10,\n",
       "         1827,    10,  3208,    10,  5764,    10,   486,    10,  1192,    10,\n",
       "         8746,    10], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(learn.data.valid_dl))\n",
    "preds = learn.model(x,y)\n",
    "preds[0][0,:].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_itos = data.label_list.train.x.vocab.itos\n",
    "y_itos = data.label_list.train.y.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj the xxmaj commission can not accept amendments 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 , 239 , 240 ,\n",
      "xxbos xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 ,\n",
      "xxbos xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , cualificado , estratégico , 110 , 111 , 112 , consideramos , vea , pesca , inglés , hablemos , 133 , schengen , informe , asuntos , 137 , correcciones , contabilidad , 150 , fósiles , 152 , doyle , eso , son , nuestra , 160 , reconciliación , factor , propietarios , preocupación , supuesto , vigilancia , 170 , universidades , previsión , las , apoyo , encuentros , martin , retórica , ? , deporte , finalmente , sobre , 4 , emisión , financiar , restricciones , son , convencidos , deficiente , ilegal , socialistas , emisión , oportunidad , excepción , salida , digan , 1 , 30 , mirando ,\n",
      "\n",
      "xxbos xxmaj the xxmaj commission can accept the following amendments : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 and 164 to 209 .\n",
      "xxbos xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 y 164 a 209 .\n",
      "xxbos xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , su , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , audiovisuales , propone , 103 , partidarios , conveniencia , otoño , 108 , 111 , 112 , alguna , formular , precisas , normalización , 120 , staes , tan , 2004 , explica , queremos , enfrenta , importación , 137 , relieve , 140 , sr. , 142 , capital , sido , 145 , mundialización , europeos , voz , arquitectura , 150 , , 152 , australia , mismos , contener , por , estudiantes y alcance a equilibrado .\n",
      "\n",
      "xxbos xxmaj the next item is the oral question to the xxmaj commission ( xxup b5 - 0206 / 2000 ) by xxmaj mr xxmaj lannoye , xxmaj mrs xxmaj auroi , xxmaj mr xxmaj bouwman , xxmaj mr xxmaj bowe , xxmaj mrs xxmaj cerdeira xxmaj morterero , xxmaj mrs xxmaj corbey , xxmaj mr xxmaj costa xxmaj paolo , xxmaj mr xxmaj deprez , xxmaj mr xxmaj desama , xxmaj mrs xxmaj gonzález xxmaj álvarez , xxmaj mrs xxmaj guy - xxmaj quint , xxmaj mr xxmaj izquierdo xxmaj collado , xxmaj mr xxmaj jonckheer , xxmaj mrs xxmaj korhola , xxmaj mr xxmaj kreissl - xxmaj dörfler , xxmaj mrs xxmaj lienemann , xxmaj mrs xxmaj lucas , xxmaj mrs mckenna , xxmaj mrs xxmaj maes , xxmaj mr xxmaj martínez xxmaj martínez , xxmaj mr xxmaj papayannakis , xxmaj mrs xxmaj patrie , xxmaj mr xxmaj arvidsson , xxmaj mr xxmaj puerta , xxmaj mr xxmaj ries , xxmaj mr xxmaj rod , xxmaj mr de xxmaj roo , xxmaj mrs xxmaj sandbæk , xxmaj mrs xxmaj schroedter , xxmaj mrs xxmaj sornosa xxmaj martínez , xxmaj mr xxmaj staes , xxmaj mr xxmaj sterckx , xxmaj mrs xxmaj terrón i xxmaj cusí , xxmaj mrs xxmaj van xxmaj brempt , xxmaj mr xxmaj vander xxmaj taelen , xxmaj mrs xxmaj van xxmaj lancker and xxmaj mr xxmaj ducarme , regarding night flights and noise pollution around airports .\n",
      "xxbos xxmaj de conformidad con el orden del orden del día se procede a la pregunta oral formulada a la xxmaj comisión por los diputados xxmaj lannoye , xxmaj auroi , xxmaj bouwman , xxmaj bowe , xxmaj cerdeira xxmaj morterero , xxmaj corbey , xxmaj costa xxmaj paolo , xxmaj deprez , xxmaj desama , xxmaj gonzález xxmaj álvarez , xxmaj guy - xxmaj quint , xxmaj izquierdo xxmaj collado , xxmaj jonckheer , xxmaj korhola , xxmaj kreissl - xxmaj dörfler , xxmaj lienemann , xxmaj lucas , mckenna , xxmaj maes , xxmaj martínez xxmaj martínez , xxmaj papayannakis , xxmaj patrie , xxmaj arvidsson , xxmaj puerta , xxmaj ries , xxmaj rod , de xxmaj roo , xxmaj sandbæk , xxmaj schroedter , xxmaj sornosa xxmaj martínez , xxmaj staes , xxmaj sterckx , xxmaj terrón i xxmaj cusí , xxmaj van xxmaj brempt , xxmaj vander xxmaj taelen , xxmaj van xxmaj lancker , xxmaj ducarme , sobre los vuelos nocturnos y las molestias sonoras en las cercanías de los aeropuertos ( xxup b5 - 0206 / 2000 ) .\n",
      "xxbos xxmaj de conformidad con el orden del orden del día se procede a la pregunta oral formulada a la xxmaj comisión por los diputados xxmaj lannoye , xxmaj temas , xxmaj posible , xxmaj bowe , xxmaj desempeña xxmaj 55 , xxmaj corbey , xxmaj costa xxmaj cielo , xxmaj deprez , xxmaj mundial , xxmaj gonzález xxmaj límite , xxmaj proyecto - xxmaj cursos , xxmaj izquierdo xxmaj resulta , xxmaj finalidad , xxmaj korhola , xxmaj kreissl - xxmaj dörfler , xxmaj el , xxmaj lucas , mckenna , xxmaj maes , xxmaj martínez xxmaj martínez , xxmaj papayannakis , xxmaj patrie , xxmaj pueda , xxmaj puerta , xxmaj ries , xxmaj suscitar , de xxmaj roo , xxmaj políticos , xxmaj schroedter , xxmaj el xxmaj martínez , xxmaj staes , xxmaj sterckx , xxmaj londres i xxmaj al , xxmaj van xxmaj huelga , xxmaj hayamos xxmaj egipto , xxmaj van xxmaj lancker , xxmaj mercado , sobre los vuelos nocturnos y las molestias quizá en las grupos de los aeropuertos ( xxup b5 - consiste / 2000 ) .\n",
      "\n",
      "xxbos - xxup a5 - 0212 / 2004 by xxmaj mr xxmaj mulder , on the discharge to the xxmaj european xxmaj agency for xxmaj reconstruction for the financial year 2002 ( xxup c5 - 0632 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for xxmaj safety and xxmaj health at xxmaj work for the financial year 2002 ( xxup c5 - 0636 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj environment xxmaj agency for the financial year 2002 ( xxup c5 - 0635 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for the xxmaj evaluation of xxmaj medicinal xxmaj products for the financial year 2002 ( xxup c5 - 0638 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj translation xxmaj centre for the xxmaj bodies of the xxmaj european xxmaj union for the financial year 2002 ( xxup c5 - 0637 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj centre for the xxmaj development of xxmaj vocational xxmaj training for the financial year 2002 ( xxup c5 - 0630 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to xxmaj eurojust\n",
      "xxbos xxmaj fundación xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - 0631 / 2003 – 2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj toxicomanías ( xxup c5 - 0634 / 2003 – 2003 / xxup xxunk ) ) ; 11 .\n",
      "xxbos xxmaj fundación xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - le / 2003 – 2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj y ( xxup c5 - 75 / 2003 – 2003 / xxup xxunk ) ) ; 11 .\n",
      "\n",
      "xxbos xxmaj oral question ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) by xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj xxunk xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj antonia xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk and xxmaj lennart xxmaj sacrédeus - xxmaj media concentration and pluralism\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) de xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj clemente xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj xxunk xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk y xxmaj lennart xxmaj sacrédeus - xxmaj concentración y pluralismo de los medios de comunicación\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - seré / 02 ) de xxmaj xxunk xxmaj primero , xxmaj marcar xxmaj distorsiones , xxmaj atentos xxmaj informado xxmaj además , xxmaj interlocutores xxmaj per , xxmaj juan xxmaj josé xxmaj enviar de xxmaj instalaciones , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj anteproyecto xxmaj este , xxmaj criticar xxmaj collins , xxmaj diaria xxmaj cornillet , xxmaj paul xxmaj con , xxmaj detrás xxmaj crowley , xxmaj anteproyecto xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj resultado xxup xxunk xxmaj deprez , xxmaj parecer xxmaj dimitrakopoulos , xxmaj número xxmaj fatuzzo , xxmaj ese xxmaj sí xxmaj es , xxmaj xxunk xxmaj ya , xxmaj resolución xxmaj visto , xxmaj internas xxmaj hatzidakis , xxmaj orden xxmaj que , xxmaj mercancías xxmaj 20 , xxmaj franco xxmaj xxunk , xxmaj necesitamos xxmaj desafío xxmaj xxunk , xxmaj trata xxmaj responsable , xxmaj juan xxmaj estadounidense xxmaj considera , xxmaj electricidad ó xxmaj uso , xxmaj iraq xxmaj xxmaj xxmaj exportación , xxmaj josé xxmaj éste xxmaj conduce , xxmaj conmigo xxmaj xxunk , xxmaj maría xxmaj xxunk xxmaj avilés xxmaj quiero , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj ha xxmaj personalidades y xxmaj perfectamente xxmaj sacrédeus - xxmaj concentración y pluralismo de los medios de comunicación\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(5):\n",
    "    print(' '.join([x_itos[o] for o in x[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in y[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in preds[0][i,:].argmax(dim=1) if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " torch.Size([16, 255]),\n",
       " torch.Size([1, 255, 300]),\n",
       " tensor([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "            0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1]]]], device='cuda:0', dtype=torch.uint8))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, src_mask = learn.model.encode_source(x[i,:].unsqueeze(0))\n",
    "i,x.shape,inp.shape,src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 252, 58838])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = learn.model.decode_target(inp, src_mask, y[i,:].unsqueeze(0))\n",
    "learn.model.tgt_word_prj(targ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     5,    51,    65,     6,  1217,    59,  3549,   149,   658,\n",
       "            60,     9,    11,     5,   333,     5,   690,    10,    14,   224,\n",
       "             9,    11,     5,    35,     9,     5,   613,    16,     5,    90,\n",
       "             5,  1205,    10,    33,    11,    92,     9,     5,   140,    20,\n",
       "             5,    49,    22,    11,    13,    21,  8765,    28,   104,    17,\n",
       "            19,  1395, 10063,  1147,    11,     5,   140,  7383,   149,  1803,\n",
       "           149,     6,  2960,   594,    17,    11,  2273,     9,    19,  5045,\n",
       "             9,  3163,  3273,    10,    11,     5,   140,  7383,   149,  7264,\n",
       "           149,     6,  2960,   594,    17,    11,  2273,     9,    19,  5045,\n",
       "             9,  4806,    10,    11,     5,   140,  7251,   149,  2023,   149,\n",
       "             6,  2960,  2657,    17,    11,  2273,     9,    18,  2397,     9,\n",
       "          9219,  8080,     9,    11,   370,    10,    11,     5,   140,  6045,\n",
       "           149,  4283,   149,     6,  2960,   594,    17,    11,  2273,     9,\n",
       "           303,     9,  6349,    16,     9,  2397,     9,  9219,     9,  6349,\n",
       "            10,   910,     9,    19,  5045,    10,    11,     5,   140,  6045,\n",
       "           149,  4712,   149,     6,  2960,   594,    17,    11,  2273,     9,\n",
       "          2397,     9,  9219,     9,  5815,    16,     9,  3251,     9,  5020,\n",
       "          1966,    17,    11,   489,  1950,    10,    11,     5,   140,  6467,\n",
       "           149,  6428,   149,     6,  1359,   594,    17,    11,  2273,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.tgt_word_prj(targ).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x, y):\n",
    "        #encode layers\n",
    "        inp, src_mask = self.encode_source(x)\n",
    "        targ = self.decode_target(inp, src_mask, y)\n",
    "        decoded = self.tgt_word_prj(targ) * self.x_logit_scale\n",
    "        return [decoded, inp, targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 252])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory, src_mask = learn.model.encode_source(x[i,:].unsqueeze(0))\n",
    "# ys = torch.ones(1, 1).fill_(learn.data.vocab.stoi[BOS]).type_as(x.data)\n",
    "# ys = torch.ones(1, 1).fill_(42).type_as(x.data)\n",
    "\n",
    "## make the y's side right!!! other wise POS encoding is wrong!\n",
    "ys = torch.ones(1, 252).type_as(x.data)\n",
    "ys[0][0] = 2\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "max_len=3\n",
    "for _ in range(max_len-1):\n",
    "    out = learn.model.decode_target(memory, src_mask, ys)[:,-1,:] #latest word estimate, can't change history.\n",
    "    prob = F.softmax(learn.model.tgt_word_prj(out),dim=-1)\n",
    "    next_i = learn.model.tgt_word_prj(out).argmax(dim=-1).item()\n",
    "    ys = torch.cat([ys, torch.ones(1,1).type_as(x.data).fill_(next_i)],dim=1)\n",
    "    print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward>), tensor([[1]], device='cuda:0'))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob, torch.multinomial(prob,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     5,    51,    65,     6,  1217,    59,  3549,   149,   658,\n",
       "            60,     9,    11,     5,   333,     5,   690,    10,    14,   224,\n",
       "             9,    11,     5,    35,     9,     5,   613,    16,     5,    90,\n",
       "             5,  1205,    10,    33,    11,    92,     9,     5,   140,    20,\n",
       "             5,    49,    22,    11,    13,    21,  8765,    28,   104,    17,\n",
       "            19,  1395, 10063,  1147,    11,     5,   140,  7383,   149,  1803,\n",
       "           149,     6,  2960,   594,    17,    11,  2273,     9,    19,  5045,\n",
       "             9,  3163,  3273,    10,    11,     5,   140,  7383,   149,  7264,\n",
       "           149,     6,  2960,   594,    17,    11,  2273,     9,    19,  5045,\n",
       "             9,  4806,    10,    11,     5,   140,  7251,   149,  2023,   149,\n",
       "             6,  2960,  2657,    17,    11,  2273,     9,    18,  2397,     9,\n",
       "          9219,  8080,     9,    11,   370,    10,    11,     5,   140,  6045,\n",
       "           149,  4283,   149,     6,  2960,   594,    17,    11,  2273,     9,\n",
       "           303,     9,  6349,    16,     9,  2397,     9,  9219,     9,  6349,\n",
       "            10,   910,     9,    19,  5045,    10,    11,     5,   140,  6045,\n",
       "           149,  4712,   149,     6,  2960,   594,    17,    11,  2273,     9,\n",
       "          2397,     9,  9219,     9,  5815,    16,     9,  3251,     9,  5020,\n",
       "          1966,    17,    11,   489,  1950,    10,    11,     5,   140,  6467,\n",
       "           149,  6428,   149,     6,  1359,   594,    17,    11,  2273,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = learn.model.decode_target(memory, src_mask, y[i,:].unsqueeze(0))\n",
    "learn.model.tgt_word_prj(targ).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow modification of prior words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "memory, src_mask = learn.model.encode_source(x[i,::].unsqueeze(0))\n",
    "ys = torch.ones(1, 1).fill_(learn.data.vocab.stoi[BOS]).type_as(x.data)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 300])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = learn.model.decode_target(memory, src_mask, ys)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]], device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.tgt_word_prj(out).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "prob = F.softmax(learn.model.tgt_word_prj(out),dim=-1)\n",
    "next_i = learn.model.tgt_word_prj(out).argmax(dim=-1).item()\n",
    "ys = torch.cat([ys, torch.ones(1,1).type_as(x.data).fill_(next_i)],dim=1)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.tgt_word_prj(learn.model.decode_target(memory, src_mask, ys)).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(prob.squeeze(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.tgt_word_prj(out).argmax(dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=10\n",
    "for i in range(max_len-1):\n",
    "\n",
    "    out = model.decoder(Variable(ys), memory, src_mask, Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
    "    prob = F.softmax(model.out(out[:, -1]))\n",
    "    #_, next_word = torch.max(prob, dim = 1)\n",
    "    next_word = torch.multinomial(prob, 1)\n",
    "    next_word = next_word.data[0][0]\n",
    "    ys = torch.cat([ys, \n",
    "                    torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to separate encoder/decoder parts.\n",
    "### Tranaslation will be:\n",
    "# * Set state from src sentence in encoder (torch.no_grad() to keep state?)\n",
    "# * start with xxbos token\n",
    "# * proceed through each step with next word (example below)\n",
    "# * OR:  beam_search() to get best set of next words up to end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can we use this encoder as a LM for english??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
