{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMT (seq2seq) in fastai v1\n",
    "\n",
    "Start with this:<br>\n",
    "https://gist.github.com/ohmeow/fe91aed6267cd779946ab9f10eccdab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split, build DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    x_max_len = max([len(s[0]) for s in samples])\n",
    "    y_max_len = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    return x_res, y_res\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for classification.  Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/seq2seq/')\n",
    "bs = 64\n",
    "\n",
    "## load the saved data.\n",
    "data = load_data(PATH, \"full_es_en_data_spacyTok.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 255]), torch.Size([64, 252]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(data.train_dl))\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([255])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][12,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541, 58838)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), len(data.label_list.train.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'the',\n",
       "  ',',\n",
       "  '.',\n",
       "  'of',\n",
       "  'to',\n",
       "  'and',\n",
       "  'in',\n",
       "  'that',\n",
       "  'a',\n",
       "  'is',\n",
       "  'we'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), data.label_list.train.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58838,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'de',\n",
       "  ',',\n",
       "  'la',\n",
       "  '.',\n",
       "  'que',\n",
       "  'en',\n",
       "  'el',\n",
       "  'y',\n",
       "  'a',\n",
       "  'los',\n",
       "  'las'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.y.vocab.itos), data.label_list.train.y.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model for Seq2Seq\n",
    "\n",
    "Big help from this link from the old course + looking at the `Transformer` code and adapting <br>\n",
    "https://github.com/kheyer/ML-DL-Projects/blob/master/Seq2Seq%20Transformer/Transformer.ipynb\n",
    "\n",
    "and here:<br>\n",
    "https://nbviewer.jupyter.org/github/fastai/fastai/blob/6ba17b21599a6fc441794ffd130bc31b5333b4a0/courses/dl2/translate.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], requires_grad=False).cuda()\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"MutiHeadAttention.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., dropout:float=0.2, bias:bool=True,\n",
    "                 scale:bool=True):\n",
    "        super().__init__()\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
    "        self.att_q = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_k = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_v = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
    "        self.drop_att,self.drop_res = nn.Dropout(dropout),nn.Dropout(resid_p)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None, **kwargs):\n",
    "        \"attn -> Linear -> drop -> merge -> LN\"\n",
    "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask, **kwargs))))\n",
    "    \n",
    "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
    "        bs,x_len = q.size(0),q.size(1) # bs x bptt x d_model\n",
    "        wq,wk,wv = self.att_q(q), self.att_k(k), self.att_v(v)\n",
    "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
    "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
    "        attn_score = torch.matmul(wq, wk)\n",
    "        if self.scale: attn_score.div_(self.d_head ** 0.5)\n",
    "        if mask is not None: \n",
    "            mask = mask.unsqueeze(1)\n",
    "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
    "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
    "        attn_vec = torch.matmul(attn_prob, wv)\n",
    "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, x_len, -1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_activ_func = {Activation.ReLU:nn.ReLU(inplace=True), Activation.GeLU:GeLU(), Activation.Swish: Swish}\n",
    "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., act:Activation=Activation.ReLU, double_drop:bool=True):\n",
    "    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n",
    "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
    "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
    "    \n",
    "class EncDecLayer(nn.Module):\n",
    "    \"Decoder block for seq2seq. Self and target attention combined.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0.2, ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=MultiHeadAttention, is_decode=False):\n",
    "        super().__init__()\n",
    "        self.is_decode = is_decode\n",
    "        self.mhra_s    = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, dropout=attn_p, bias=bias, scale=scale)\n",
    "        if self.is_decode:\n",
    "            self.mhra_targ = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, dropout=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "        \n",
    "    def forward(self, x:Tensor, enc_out:Tensor=None, src_mask:Tensor=None, trg_mask:Tensor=None, **kwargs):\n",
    "        assert self.is_decode == (enc_out is not None), \"Calling Decode `forward()` with out init `is_decode`\"\n",
    "        ## I think I had the wrong masks here, had them flipped around.\n",
    "        x = self.mhra_s(x,x,x, mask=trg_mask if self.is_decode else src_mask, **kwargs)\n",
    "        if self.is_decode: x = self.mhra_targ(x, enc_out, enc_out, mask=src_mask, **kwargs)\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncDec(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, is_decode=False):\n",
    "        super().__init__()\n",
    "        self.is_decode = is_decode\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, 255)\n",
    "        self.layers = nn.ModuleList([EncDecLayer(heads, d_model, d_head=d_model//heads, d_inner=2048, is_decode=is_decode) \n",
    "                                         for k in range(N)])\n",
    "    \n",
    "    def forward(self, x, e_outputs=None, src_mask=None, trg_mask=None):\n",
    "        x = self.pe(self.embed(x))\n",
    "        if (not self.is_decode) and (e_outputs is None):\n",
    "            for layer in self.layers:  x = layer(x,src_mask=src_mask)\n",
    "        elif self.is_decode:\n",
    "            for layer in self.layers:  x = layer(x, e_outputs, src_mask, trg_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = EncDec(src_vocab, d_model, N, heads)\n",
    "        self.decoder = EncDec(trg_vocab, d_model, N, heads, is_decode=True)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "        \n",
    "    def reset(self): pass\n",
    "    \n",
    "    def forward(self, src, trg, src_mask=None, trg_mask=None):\n",
    "        if src_mask is None: src_mask, trg_mask = create_masks(src, trg)\n",
    "        e_outputs = self.encoder(src, src_mask=src_mask)\n",
    "        d_output  = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return [output, output, output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "torch.tril(torch.ones((size,size)), diagonal=0).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones((size,size)), diagonal=1).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nopeak_mask(size):\n",
    "    \"valid view locations lower trianglular including diagonal\"\n",
    "    return torch.triu(torch.ones((size,size)), diagonal=1).byte().unsqueeze(0)\n",
    "\n",
    "def create_masks(src, trg=None):\n",
    "    \"masks for nopeak and remove padding from training\"\n",
    "    src_mask = (src == 1).unsqueeze(-2)\n",
    "    if trg is not None: trg_mask = (trg == 1).unsqueeze(-2) | nopeak_mask(trg.size(1)).cuda() #change to or?\n",
    "    else: trg_mask = None\n",
    "\n",
    "    return src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 150\n",
    "heads = 3\n",
    "N = 3\n",
    "\n",
    "src_vocab = len(data.label_list.train.x.vocab.itos)\n",
    "trg_vocab = len(data.label_list.train.y.vocab.itos)\n",
    "model = to_device(Transformer(src_vocab, trg_vocab, d_model, N, heads), defaults.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): EncDec(\n",
       "    (embed): Embedding(35541, 150)\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): EncDec(\n",
       "    (embed): Embedding(58838, 150)\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mhra_targ): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mhra_targ): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncDecLayer(\n",
       "        (mhra_s): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mhra_targ): MultiHeadAttention(\n",
       "          (att_q): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_k): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (att_v): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (out): Linear(in_features=150, out_features=150, bias=True)\n",
       "          (drop_att): Dropout(p=0.2)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=150, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=150, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([150]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=150, out_features=58838, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    \"Include the target in the training loop for Decoder mask\"\n",
    "    learn:Learner\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target[:,:-1]),\n",
    "                'last_target':last_target[:,1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLearner(RNNLearner):\n",
    "    \"Subclass of RNNLearner for predictions using Seq2Seq\"\n",
    "    \n",
    "    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None, sep:str=' ',\n",
    "                decoder=decode_spec_tokens):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        ## handle predictions for Seq2Seq\n",
    "        set_trace()\n",
    "        ds = self.data.single_dl.dataset\n",
    "        self.model.reset()\n",
    "        xb,yb = self.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(n_words): #progress_bar(range(n_words), leave=False):\n",
    "            res = self.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            #if len(new_idx) == 0: self.model[0].select_hidden([0])\n",
    "            if no_unk: res[self.data.vocab.stoi[UNK]] = 0.\n",
    "            if min_p is not None: res[res < min_p] = 0.\n",
    "            if temperature != 1.: res.pow_(1 / temperature)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        return text + sep + sep.join(decoder(self.data.vocab.textify(new_idx, sep=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Seq2SeqLearner(data, model, **{'alpha':0,'beta':0}, callbacks=[AppendBatchTargs()], loss_func=CrossEntropyFlat())\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27,560,876'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
    "f'{total_params:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in learn.model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 24  ## 64 fails to load.  Prob. too big embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "lr_find(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 45:14 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>1.253895</th>\n",
       "    <th>1.284659</th>\n",
       "    <th>45:14</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, max_lr=1e-3)  #flipping the mask seemed to have caused a problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    2,     5,     9,  ...,    10, 12170,    10],\n",
       "         [    2,     5,     9,  ...,     1,     1,     1],\n",
       "         [    2,     5,     9,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    2,     5,     9,  ...,     1,     1,     1],\n",
       "         [    2,     5,     9,  ...,     1,     1,     1],\n",
       "         [    2,     5,     9,  ...,     1,     1,     1]], device='cuda:0'),\n",
       " tensor([    2,     5,    11,     5,    35,    23,    83,   621,    19,   209,\n",
       "           486,    10,   724,    10,   820,    10,   952,    10,  1210,    10,\n",
       "          1414,    10,  1657,    10,  1322,    10,  1471,    10,   985,    10,\n",
       "          1880,    10,  2167,    10,  2270,    10,  2091,    10,   909,    10,\n",
       "          1803,    10,  2664,    10,  2780,    10,  1192,    10,  2596,    10,\n",
       "          4019,    10,  4283,    10,  3091,    10,  3651,    10,  4856,    10,\n",
       "          4271,    10,  4792,    10,  4964,    10,  3745,    10,  5538,    10,\n",
       "          5664,    10,  4074,    10,  5296,    10,  5858,    10,  6064,    10,\n",
       "          6978,    10,  4424,    10,  6428,    10,  6963,    10,  6632,    10,\n",
       "          7383,    10,  8393,    10,  2530,    10,  5315,    10,  4053,    10,\n",
       "          7715,    10,  2282,    10,  7931,    10, 11149,    10,  5890,    10,\n",
       "          8345,    10,  2640,    10,  7729,    10,  6045,    10,  7007,    10,\n",
       "          8048,    10,  3974,    10,  5856,    10,  6467,    10,  6407,    10,\n",
       "          1988,    10, 15977,    10, 13748,    10,  7522,    10, 12517,    10,\n",
       "         10790,    10, 15227,    10, 16670,    10, 16074,    10, 17804,    10,\n",
       "         12880,    10, 11224,    10, 20126,    10, 15976,    10, 20389,    10,\n",
       "          6896,    10, 17382,    10, 15755,    10,  4629,    10, 14021,    10,\n",
       "          9174,    10, 17581,    10, 19823,    10, 19093,    10, 17806,    10,\n",
       "         11180,    10, 14171,    10, 20866,    10, 15736,    10, 19540,    10,\n",
       "         17966,    10, 14159,    10, 10778,    10, 21733,    10, 22931,    10,\n",
       "         21069,    10, 23074,    10, 18062,    10, 24469,    10, 23876,    10,\n",
       "         21097,    10, 29554,    10, 28008,    10, 34727,    10, 36166,    10,\n",
       "         43624,    10, 37291,    10, 30171,    10, 32310,    10, 20367,    10,\n",
       "         17047,    10, 37106,    10, 27187,    10, 29630,    10, 15360,    10,\n",
       "         32927,    10, 29078,    10, 39909,    10, 32249,    10, 31073,    10,\n",
       "         30475,    10], device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(learn.data.valid_dl))\n",
    "x,y[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5,   11,    5,   35,   23,   83,  621,   19,  209,  486,   10,  724,\n",
       "          10,  820,   10,  952,   10, 1210,   10, 1414,   10, 1657,   10, 1322,\n",
       "          10, 1471,   10, 1471,   10, 1880,   10, 2167,   10, 2270,   10, 2091,\n",
       "          10, 1803,   10, 1803,   10, 2780,   10, 2780,   10, 1192,   10, 2596,\n",
       "          10, 4019,   10, 4283,   10, 3651,   10, 3651,   10, 3651,   10, 4856,\n",
       "          10, 4964,   10, 4964,   10, 3745,   10, 5538,   10, 3745,   10, 4074,\n",
       "          10, 4074,   10, 4074,   10, 6064,   10, 6428,   10, 6428,   10, 6428,\n",
       "          10, 6428,   10, 6428,   10, 2530,   10, 5890,   10, 5890,   10, 5890,\n",
       "          10, 5890,   10, 5890,   10, 5890,   10, 5890,   10, 5890,   10, 5890,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10,    1,   10,    1,   10,    1,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10,    1,\n",
       "          10,    1,   10,    1,   10,    1,   10,    1,   10,    1,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10,    1,   10,    1,   10,    1,   10,    1,   10,    1,   10,    1,\n",
       "          10,    1,   10,    1,   10,    1,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10,    1,   10,    1,   10,    1,\n",
       "          10,    1,   10,    1,   10,    1,   10, 7007,   10, 7007,   10, 7007,\n",
       "          10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007,   10, 7007],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = learn.model(x,y)\n",
    "preds[0][0,:].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_itos = data.label_list.train.x.vocab.itos\n",
    "y_itos = data.label_list.train.y.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj the xxmaj commission can not accept amendments 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 , 239 , 240 ,\n",
      "xxbos xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 ,\n",
      "xxmaj la xxmaj comisión no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 13 , 17 , 22 , 23 , 24 , 27 , 27 , 29 , 29 , 30 , 31 , 32 , 33 , 37 , 37 , 37 , 38 , 44 , 44 , 45 , 46 , 45 , 48 , 48 , 48 , 52 , 56 , 56 , 56 , 56 , 56 , 70 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , , , , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , , , , , , , 93 , 93 , 93 , 93 , 93 , 93 , 93 , , , , , , , , , , 93 , 93 , 93 , 93 , 93 , 93 , , , , , , , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93\n",
      "\n",
      "xxbos xxmaj the xxmaj commission can accept the following amendments : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 and 164 to 209 .\n",
      "xxbos xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 y 164 a 209 .\n",
      "xxmaj la xxmaj comisión puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 19 , 19 , 23 , 24 , 26 , 26 , 27 , 29 , 5 , 93 , 42 , 47 , 33 , 37 , 37 , 37 , 39 , 39 , 39 , 39 , 44 , 45 , 45 , 45 , 45 , 45 , 53 , 56 , 56 , 56 , 56 , 56 , 56 , 61 , 61 , 61 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 93 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 85 , 93 , 93 , 93 , 93 , 43 , 43 ,\n",
      "\n",
      "xxbos xxmaj the next item is the oral question to the xxmaj commission ( xxup b5 - 0206 / 2000 ) by xxmaj mr xxmaj lannoye , xxmaj mrs xxmaj auroi , xxmaj mr xxmaj bouwman , xxmaj mr xxmaj bowe , xxmaj mrs xxmaj cerdeira xxmaj morterero , xxmaj mrs xxmaj corbey , xxmaj mr xxmaj costa xxmaj paolo , xxmaj mr xxmaj deprez , xxmaj mr xxmaj desama , xxmaj mrs xxmaj gonzález xxmaj álvarez , xxmaj mrs xxmaj guy - xxmaj quint , xxmaj mr xxmaj izquierdo xxmaj collado , xxmaj mr xxmaj jonckheer , xxmaj mrs xxmaj korhola , xxmaj mr xxmaj kreissl - xxmaj dörfler , xxmaj mrs xxmaj lienemann , xxmaj mrs xxmaj lucas , xxmaj mrs mckenna , xxmaj mrs xxmaj maes , xxmaj mr xxmaj martínez xxmaj martínez , xxmaj mr xxmaj papayannakis , xxmaj mrs xxmaj patrie , xxmaj mr xxmaj arvidsson , xxmaj mr xxmaj puerta , xxmaj mr xxmaj ries , xxmaj mr xxmaj rod , xxmaj mr de xxmaj roo , xxmaj mrs xxmaj sandbæk , xxmaj mrs xxmaj schroedter , xxmaj mrs xxmaj sornosa xxmaj martínez , xxmaj mr xxmaj staes , xxmaj mr xxmaj sterckx , xxmaj mrs xxmaj terrón i xxmaj cusí , xxmaj mrs xxmaj van xxmaj brempt , xxmaj mr xxmaj vander xxmaj taelen , xxmaj mrs xxmaj van xxmaj lancker and xxmaj mr xxmaj ducarme , regarding night flights and noise pollution around airports .\n",
      "xxbos xxmaj de conformidad con el orden del orden del día se procede a la pregunta oral formulada a la xxmaj comisión por los diputados xxmaj lannoye , xxmaj auroi , xxmaj bouwman , xxmaj bowe , xxmaj cerdeira xxmaj morterero , xxmaj corbey , xxmaj costa xxmaj paolo , xxmaj deprez , xxmaj desama , xxmaj gonzález xxmaj álvarez , xxmaj guy - xxmaj quint , xxmaj izquierdo xxmaj collado , xxmaj jonckheer , xxmaj korhola , xxmaj kreissl - xxmaj dörfler , xxmaj lienemann , xxmaj lucas , mckenna , xxmaj maes , xxmaj martínez xxmaj martínez , xxmaj papayannakis , xxmaj patrie , xxmaj arvidsson , xxmaj puerta , xxmaj ries , xxmaj rod , de xxmaj roo , xxmaj sandbæk , xxmaj schroedter , xxmaj sornosa xxmaj martínez , xxmaj staes , xxmaj sterckx , xxmaj terrón i xxmaj cusí , xxmaj van xxmaj brempt , xxmaj vander xxmaj taelen , xxmaj van xxmaj lancker , xxmaj ducarme , sobre los vuelos nocturnos y las molestias sonoras en las cercanías de los aeropuertos ( xxup b5 - 0206 / 2000 ) .\n",
      "xxmaj de conformidad con el orden del día del día , procede a la pregunta oral a por la xxmaj comisión ( el xxmaj xxmaj lannoye , xxmaj sra. , xxmaj sr. , xxmaj sr. , xxmaj sra. xxmaj rühle , xxmaj sra. , xxmaj sra. de sr. xxmaj xxmaj sra. , xxmaj sra. , xxmaj costa , costa , xxmaj sr. xxmaj xxmaj xxunk , xxmaj sr. xxmaj wogau , xxmaj sra. , xxmaj sra. , xxmaj sra. - xxmaj diferencia , xxmaj sra. , xxmaj sra. , xxmaj , xxmaj sra. , xxmaj sr. , aprueba , xxmaj sra. , xxmaj sra. , xxmaj sra. , xxmaj sra. , xxmaj sra. , xxmaj sra. , xxmaj la sra. , xxmaj sra. , xxmaj sra. , xxmaj sra. xxmaj sra. , xxmaj sra. , xxmaj sra. , xxmaj sra. xxmaj xxmaj sra. , xxmaj sra. xxmaj martínez , xxmaj sra. xxmaj martínez , xxmaj sra. xxmaj martínez , xxmaj martínez , xxmaj xxmaj xxmaj xxmaj , xxmaj xxmaj xxmaj , xxmaj xxmaj , la xxmaj xxmaj xxmaj xxunk - xxmaj , xxmaj , , xxmaj\n",
      "\n",
      "xxbos - xxup a5 - 0212 / 2004 by xxmaj mr xxmaj mulder , on the discharge to the xxmaj european xxmaj agency for xxmaj reconstruction for the financial year 2002 ( xxup c5 - 0632 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for xxmaj safety and xxmaj health at xxmaj work for the financial year 2002 ( xxup c5 - 0636 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj environment xxmaj agency for the financial year 2002 ( xxup c5 - 0635 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for the xxmaj evaluation of xxmaj medicinal xxmaj products for the financial year 2002 ( xxup c5 - 0638 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj translation xxmaj centre for the xxmaj bodies of the xxmaj european xxmaj union for the financial year 2002 ( xxup c5 - 0637 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj centre for the xxmaj development of xxmaj vocational xxmaj training for the financial year 2002 ( xxup c5 - 0630 / 2003 – 2003 / xxup xxunk ) ) ; on the discharge to xxmaj eurojust\n",
      "xxbos xxmaj fundación xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - 0631 / 2003 – 2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj toxicomanías ( xxup c5 - 0634 / 2003 – 2003 / xxup xxunk ) ) ; 11 .\n",
      "- informe xxmaj europea para la xxmaj reconstrucción de la xxmaj redes de xxmaj reconstrucción / xxmaj 2004 programa ( xxup c5 - xxunk / 2003 - xxup / xxup xxunk ) ; ; xxmaj / xxmaj sobre de europeo de la xxmaj redes y xxmaj xxmaj redes para xxup c5 - xxunk / 2003 - 2003 - xxup xxunk ) ) ; sobre -\n",
      "\n",
      "xxbos xxmaj oral question ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) by xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj xxunk xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj antonia xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk and xxmaj lennart xxmaj sacrédeus - xxmaj media concentration and pluralism\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) de xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj josé xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coûteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj gérard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernández xxmaj martín , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj clemente xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj seán ó xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arburúa , xxmaj josé xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj maría xxmaj xxunk xxmaj avilés xxmaj perea , xxmaj josé xxmaj javier xxmaj pomés xxmaj ruiz , xxmaj bartho xxmaj pronk y xxmaj lennart xxmaj sacrédeus - xxmaj concentración y pluralismo de los medios de comunicación\n",
      "xxmaj pregunta oral ( xxup xxunk / 02 ) xxup b5 - xxunk / 02 ) de xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk xxmaj ampliación , xxmaj xxunk xxmaj xxunk , xxmaj josé xxmaj xxunk xxmaj jerusalén de xxmaj xxunk , xxmaj josé - xxmaj josé xxmaj xxunk , xxmaj josé xxmaj financieras , xxmaj umbral xxmaj collins , xxmaj mínimo xxmaj collins , xxmaj gente xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk , xxunk xxmaj xxmaj xxunk xxmaj xxunk xxmaj xxunk xxmaj xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxunk , xxmaj xxunk xxmaj xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxunk , xxmaj xxunk xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk de xxmaj , xxmaj xxmaj de xxmaj de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(5):\n",
    "    print(' '.join([x_itos[o] for o in x[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in y[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in preds[0][i,:].argmax(dim=1) if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) != 0\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encoder(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        try: out = model.decoder(Variable(ys), memory, src_mask, Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
    "        except: set_trace()\n",
    "        prob = F.softmax(model.out(out[:, -1]))\n",
    "\n",
    "#         next_word = torch.multinomial(prob, 1)  #sample from distribution\n",
    "#         next_word = next_word.data[0][0]\n",
    "\n",
    "        next_word = prob.argmax(dim=-1).item()  ## single best\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = x\n",
    "trg = y\n",
    "trg_input = trg[:,:-1]\n",
    "# targets = trg[:, 1:].contiguous()\n",
    "src_mask, _ = create_masks(src, trg_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-47-97901b78a561>(12)greedy_decode()\n",
      "-> prob = F.softmax(model.out(out[:, -1]))\n",
      "(Pdb) subsequent_mask(ys.size(1)\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "(Pdb) subsequent_mask(ys.size(1))\n",
      "tensor([[[0]]], dtype=torch.uint8)\n",
      "(Pdb) memory\n",
      "tensor([[[ 1.0344e-03,  2.4891e-02, -1.1654e-02,  ...,  9.5091e-03,\n",
      "          -2.3380e-02, -4.1797e-03],\n",
      "         [ 6.7918e-01, -2.1549e-01, -9.1743e-02,  ..., -3.3270e-02,\n",
      "          -5.2212e-02,  4.1782e-02],\n",
      "         [ 9.1677e-01, -8.6189e-02,  1.3126e+00,  ...,  7.5200e-01,\n",
      "           7.0850e-01,  1.9494e+00],\n",
      "         ...,\n",
      "         [ 7.5165e-01, -8.5375e-01,  8.4806e-01,  ...,  1.0388e+00,\n",
      "           8.8812e-02,  1.0019e+00],\n",
      "         [ 1.1235e+00, -6.2781e-01,  1.4814e-01,  ...,  1.0388e+00,\n",
      "           8.8812e-02,  1.0019e+00],\n",
      "         [ 5.8064e-01,  1.5397e-01, -5.6147e-01,  ...,  1.0388e+00,\n",
      "           8.8812e-02,  1.0019e+00]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "(Pdb) src_mask\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0',\n",
      "       dtype=torch.uint8)\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a2e375ce757e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-97901b78a561>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         next_word = torch.multinomial(prob, 1)  #sample from distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-97901b78a561>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         next_word = torch.multinomial(prob, 1)  #sample from distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ys = greedy_decode(m, src[10].unsqueeze(0), src_mask[10], max_len=y.size(1), start_symbol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([x_itos[o] for o in src[10] if o != 1]))\n",
    "print(' '.join([y_itos[o] for o in trg[10] if o != 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([y_itos[o] for o in ys[0,:] if o != 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
