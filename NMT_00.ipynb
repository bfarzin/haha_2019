{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMT (seq2seq) in fastai v1\n",
    "\n",
    "Start with this:<br>\n",
    "https://gist.github.com/ohmeow/fe91aed6267cd779946ab9f10eccdab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farzin/haha_2019\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_es_translate.csv  es-en.tgz\teuroparl-v7.es-en.en  europarl-v7.es-en.es\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/es-en')\n",
    "\n",
    "BASE = 'europarl-v7.es-en'\n",
    "en_file = DATA_PATH/f'{BASE}.en'\n",
    "es_file = DATA_PATH/f'{BASE}.es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_sq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "lines = ((re_eq.search(eq), re_sq.search(sq)) \n",
    "          for eq, sq in zip(open(en_file, encoding='utf-8'), open(es_file, encoding='utf-8')))\n",
    "\n",
    "qs = [ {'english_text': e.group(), 'spanish_text': f.group()} for e, f in lines if e and f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'english_text': 'Why has no air quality test been done on this particular building since we were elected?',\n",
       "  'spanish_text': '¿Por qué no se ha hecho ninguna prueba de calidad del aire de este edificio desde que hemos sido elegidos?'},\n",
       " {'english_text': 'Why has there been no Health and Safety Committee meeting since 1998?',\n",
       "  'spanish_text': '¿Por qué no se ha celebrado ninguna reunión del Comité de Sanidad y Seguridad desde 1998?'},\n",
       " {'english_text': 'Why has there been no fire drill, either in the Brussels Parliament buildings or the Strasbourg Parliament buildings?',\n",
       "  'spanish_text': '¿Por qué no hemos tenido simulacros de incendio ni en los edificios del Parlamento de Bruselas ni en los del Parlamento de Estrasburgo?'},\n",
       " {'english_text': 'Why are there no fire instructions?',\n",
       "  'spanish_text': '¿Por qué no hay instrucciones en caso de incendio?'},\n",
       " {'english_text': 'Why have the staircases not been improved since my accident?',\n",
       "  'spanish_text': '¿Por qué no se han mejorado las escaleras desde mi accidente?'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_text</th>\n",
       "      <th>spanish_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why has no air quality test been done on this ...</td>\n",
       "      <td>¿Por qué no se ha hecho ninguna prueba de cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why has there been no Health and Safety Commit...</td>\n",
       "      <td>¿Por qué no se ha celebrado ninguna reunión de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why has there been no fire drill, either in th...</td>\n",
       "      <td>¿Por qué no hemos tenido simulacros de incendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why are there no fire instructions?</td>\n",
       "      <td>¿Por qué no hay instrucciones en caso de incen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why have the staircases not been improved sinc...</td>\n",
       "      <td>¿Por qué no se han mejorado las escaleras desd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english_text  \\\n",
       "0  Why has no air quality test been done on this ...   \n",
       "1  Why has there been no Health and Safety Commit...   \n",
       "2  Why has there been no fire drill, either in th...   \n",
       "3                Why are there no fire instructions?   \n",
       "4  Why have the staircases not been improved sinc...   \n",
       "\n",
       "                                        spanish_text  \n",
       "0  ¿Por qué no se ha hecho ninguna prueba de cali...  \n",
       "1  ¿Por qué no se ha celebrado ninguna reunión de...  \n",
       "2  ¿Por qué no hemos tenido simulacros de incendi...  \n",
       "3  ¿Por qué no hay instrucciones en caso de incen...  \n",
       "4  ¿Por qué no se han mejorado las escaleras desd...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(qs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_PATH/'en_es_translate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split, build DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11813, 2), (2953, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH/'en_es_translate.csv')\n",
    "\n",
    "rnd_seed = 20190313\n",
    "np.random.seed(rnd_seed)\n",
    "\n",
    "idx = np.random.permutation(len(df))\n",
    "valid_cut = int(0.20 * len(idx))\n",
    "\n",
    "train_df = df.iloc[idx[:-valid_cut],:]\n",
    "valid_df = df.iloc[idx[-valid_cut:],:]\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    x_max_len = max([len(s[0]) for s in samples])\n",
    "    y_max_len = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    return x_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for classification.  Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer(lang='en')\n",
    "es_tok = Tokenizer(lang='es')\n",
    "\n",
    "en_procs = [TokenizeProcessor(tokenizer=en_tok), NumericalizeProcessor()]\n",
    "es_procs = [TokenizeProcessor(tokenizer=es_tok), NumericalizeProcessor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/seq2seq/')\n",
    "bs = 64\n",
    "\n",
    "en_train_il = Seq2SeqTextList.from_df(train_df, path=PATH, cols=['english_text'], processor=en_procs)\n",
    "es_train_il = Seq2SeqTextList.from_df(train_df, path=PATH, cols=['spanish_text'], processor=es_procs)\n",
    "\n",
    "en_valid_il = Seq2SeqTextList.from_df(train_df, path=PATH, cols=['english_text'])\n",
    "es_valid_il = Seq2SeqTextList.from_df(train_df, path=PATH, cols=['spanish_text'])\n",
    "\n",
    "trn_ll = LabelList(en_train_il, es_train_il)\n",
    "val_ll = LabelList(en_valid_il, es_valid_il)\n",
    "\n",
    "lls = LabelLists(PATH, train=trn_ll, valid=val_ll).process()\n",
    "\n",
    "data = lls.databunch(bs=bs, val_bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052, 4658)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_train_il.vocab.itos), len(es_train_il.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 155]), torch.Size([64, 147]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(data.train_dl))\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    5,   11,  ...,    5, 1338,   10],\n",
       "        [   2,    5,   11,  ...,    1,    1,    1],\n",
       "        [   2,    5,   36,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2,    5,   36,  ...,    1,    1,    1],\n",
       "        [   2,    5,   36,  ...,    1,    1,    1],\n",
       "        [   2,    5,   18,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,   10,    5,  ..., 1791, 3303,    9],\n",
       "        [   2,   10,    5,  ...,    1,    1,    1],\n",
       "        [   2,    5,   56,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2,   10,    5,  ...,    1,    1,    1],\n",
       "        [   2,    5,   56,  ...,    1,    1,    1],\n",
       "        [   2,   10,    5,  ...,    1,    1,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052, 4658)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), len(data.label_list.train.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4052,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'the',\n",
       "  '?',\n",
       "  'what',\n",
       "  'to',\n",
       "  ',',\n",
       "  'of',\n",
       "  'is',\n",
       "  'in',\n",
       "  'and',\n",
       "  'why',\n",
       "  'we'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), data.label_list.train.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Seq2SeqDataBunch"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model for Seq2Seq\n",
    "\n",
    "Big help from this link from the old course + looking at the `Transformer` code and adapting <br>\n",
    "https://github.com/kheyer/ML-DL-Projects/blob/master/Seq2Seq%20Transformer/Transformer.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m_MultiHeadAttention(nn.Module):\n",
    "    \"MutiHeadAttention.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int=None, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
    "                 scale:bool=True):\n",
    "        super().__init__()\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale\n",
    "        self.att_q = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_k = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.att_v = nn.Linear(d_model, n_heads * d_head, bias=bias)\n",
    "        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)\n",
    "        self.drop_att,self.drop_res = nn.Dropout(attn_p),nn.Dropout(resid_p)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None, **kwargs):\n",
    "        \"attn -> Linear -> drop -> merge -> LN\"\n",
    "        return self.ln(q + self.drop_res(self.out(self._apply_attention(q, k, v, mask=mask, **kwargs))))\n",
    "    \n",
    "    def _apply_attention(self, q:Tensor, k:Tensor, v:Tensor, mask:Tensor=None):\n",
    "        bs,x_len = q.size(0),q.size(1) # bs x bptt x d_model\n",
    "        wq,wk,wv = self.att_q(q), self.att_k(k), self.att_v(v)\n",
    "        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv))\n",
    "        wq,wk,wv = wq.permute(0, 2, 1, 3),wk.permute(0, 2, 3, 1),wv.permute(0, 2, 1, 3)\n",
    "        attn_score = torch.matmul(wq, wk)\n",
    "        if self.scale: attn_score.div_(self.d_head ** 0.5)\n",
    "        if mask is not None: \n",
    "            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)\n",
    "        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1))\n",
    "        attn_vec = torch.matmul(attn_prob, wv)\n",
    "        return attn_vec.permute(0, 2, 1, 3).contiguous().contiguous().view(bs, x_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_activ_func = {Activation.ReLU:nn.ReLU(inplace=True), Activation.GeLU:GeLU(), Activation.Swish: Swish}\n",
    "def feed_forward(d_model:int, d_ff:int, ff_p:float=0., act:Activation=Activation.ReLU, double_drop:bool=True):\n",
    "    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n",
    "    if double_drop: layers.append(nn.Dropout(ff_p))\n",
    "    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))\n",
    "\n",
    "class m_EncoderLayer(nn.Module):\n",
    "    \"Basic block of a Transformer model.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=m_MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.mhra = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x:Tensor, mask:Tensor=None, **kwargs): return self.ff(self.mhra(x, x, x, mask=mask, **kwargs))\n",
    "\n",
    "class m_DecoderLayer(nn.Module):\n",
    "    \"Decoder block for seq2seq. Self and target attention combined.\"\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, act:Activation=Activation.ReLU, double_drop:bool=True,\n",
    "                 attn_cls:Callable=m_MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.mhra_s    = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.mhra_targ = attn_cls(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, act=act, double_drop=double_drop)\n",
    "        \n",
    "    def forward(self, x:Tensor, enc_out:Tensor, src_mask:Tensor=None, targ_mask:Tensor=None, **kwargs): \n",
    "        x = self.mhra_s(x,x,x, mask=targ_mask, **kwargs)\n",
    "        return self.ff(self.mhra_targ(x, enc_out, enc_out, mask=src_mask, **kwargs))\n",
    "    \n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n",
    "    def __init__(self, vocab_sz:int, tgt_vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, \n",
    "                 d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=True, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=m_MultiHeadAttention,\n",
    "                 learned_pos_enc:bool=True, mask:bool=True):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.encoder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_emb = nn.Dropout(embed_p)\n",
    "\n",
    "        self.enc_layers = nn.ModuleList([m_EncoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls) for k in range(n_layers)])\n",
    "\n",
    "        self.decoder = nn.Embedding(tgt_vocab_sz, d_model)\n",
    "        self.pos_dec = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_dec = nn.Dropout(embed_p)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([m_DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                          ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                          attn_cls=attn_cls) for k in range(n_layers)])\n",
    "        \n",
    "        self.tgt_word_prj = nn.Linear(d_model, tgt_vocab_sz, bias=False)\n",
    "        nn.init.xavier_normal_(self.tgt_word_prj.weight)\n",
    "        self.x_logit_scale = (d_model ** -0.5)\n",
    "        \n",
    "    def reset(self):pass\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        bs, x_len = x.size()\n",
    "        bs, y_len = y.size()\n",
    "        pos = torch.arange(0, x_len, device=x.device, dtype=x.dtype)\n",
    "        inp = self.drop_emb(self.encoder(x) + self.pos_enc(pos)[None]) #.mul_(self.d_model ** 0.5)\n",
    "        pos_y = torch.arange(0, y_len, device=x.device, dtype=x.dtype)\n",
    "        targ = self.drop_dec(self.decoder(y) + self.pos_dec(pos_y)[None]) #.mul_(self.d_model ** 0.5)\n",
    "\n",
    "        ## masking/padding is not yet right here.  Needs to be fixed to mask the pad IDs\n",
    "        src_mask = (x==1).byte()[:,None,None,:] #[64,5,155,155]\n",
    "        #mask == trg_mask (but trg_mask also masks out all xxpad ids [id==1]  add that here)\n",
    "        nopeak_mask = torch.triu(x.new_ones(y_len, y_len), diagonal=1).byte() if self.mask else None\n",
    "        targ_mask = (y==1).byte()[:,None,:,None] * nopeak_mask\n",
    "        \n",
    "        for layer in self.enc_layers: inp  = layer(inp, mask=src_mask)\n",
    "        for layer in self.dec_layers: targ = layer(targ, inp, src_mask=src_mask, targ_mask=targ_mask)\n",
    "        decoded = self.tgt_word_prj(targ) * self.x_logit_scale\n",
    "\n",
    "        return [decoded,decoded,decoded] #for RNN trainer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfm_seq2seq = Seq2SeqTransformer(vocab_sz=len(data.label_list.train.x.vocab.itos),\n",
    "                       tgt_vocab_sz=len(data.label_list.train.y.vocab.itos),\n",
    "                       ctx_len=256, n_layers=6, n_heads=10, d_model=300, d_head=64, d_inner=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_seq2seq = Seq2SeqTransformer(vocab_sz=len(data.label_list.train.x.vocab.itos),\n",
    "                       tgt_vocab_sz=len(data.label_list.train.y.vocab.itos),\n",
    "                       ctx_len=256, n_layers=6, n_heads=5, d_model=768, d_head=64, d_inner=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transformer(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 0., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)\n",
    "    elif classname.find('LayerNorm') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None: nn.init.normal_(m.weight, 1., 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:     nn.init.constant_(m.bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tfm_seq2seq.apply(init_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I add `on_batch_begin` to return x,y as `xb` then that is passed as `*xb` to the model and we can extract y and use for teacher forcing and proper attention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = LanguageLearner(data, tfm_seq2seq, **{'alpha':0,'beta':0}, callbacks=[AppendBatchTargs()], loss_func=CrossEntropyFlat())\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'47,327,616'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
    "f'{total_params:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "lr_find(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 15:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>6.225850</th>\n",
       "    <th>5.730264</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.681012</th>\n",
       "    <th>3.360382</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2.101718</th>\n",
       "    <th>2.061979</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.328639</th>\n",
       "    <th>1.381029</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.924974</th>\n",
       "    <th>0.974917</th>\n",
       "    <th>00:34</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.670669</th>\n",
       "    <th>0.742533</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.528195</th>\n",
       "    <th>0.588714</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.441379</th>\n",
       "    <th>0.477598</th>\n",
       "    <th>00:37</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.357678</th>\n",
       "    <th>0.393029</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.291205</th>\n",
       "    <th>0.325281</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.251417</th>\n",
       "    <th>0.269722</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.207356</th>\n",
       "    <th>0.225844</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.163753</th>\n",
       "    <th>0.188925</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.138784</th>\n",
       "    <th>0.158074</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.127663</th>\n",
       "    <th>0.132025</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.100231</th>\n",
       "    <th>0.110636</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.085608</th>\n",
       "    <th>0.091843</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.074337</th>\n",
       "    <th>0.076002</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.060619</th>\n",
       "    <th>0.062067</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.048942</th>\n",
       "    <th>0.050259</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.037507</th>\n",
       "    <th>0.040675</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>21</th>\n",
       "    <th>0.030987</th>\n",
       "    <th>0.032103</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>22</th>\n",
       "    <th>0.023763</th>\n",
       "    <th>0.025191</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>23</th>\n",
       "    <th>0.019322</th>\n",
       "    <th>0.019294</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>24</th>\n",
       "    <th>0.015404</th>\n",
       "    <th>0.014657</th>\n",
       "    <th>00:35</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## fit one cycle is just too darn agressive for Transformer. Why?\n",
    "## loss going to nearly zero means we are peaking. How?\n",
    "learn.fit(25, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcXHWd7//Xp5bu6n3JnnRCQliyL50Oi8gSQARcAEGEEQdw4Q4O48LMOKj3Nzr+LvNjRn5ccO78VFBA7hVQYRBkGQYhiqiEJBCyk4QkhOxJZ+m9uqvq8/vjnIQOZOkkXV3dVe/n41GPqjp1ls/5Qt51+ntOfY+5OyIikv8iuS5ARET6hgJfRKRAKPBFRAqEAl9EpEAo8EVECoQCX0SkQCjwRUQKhAJfRKRAKPBFRApELNcFdDd48GAfO3ZsrssQERkwFi5cuNPdh/Rk3n4V+GPHjmXBggW5LkNEZMAws3d6Oq+6dERECoQCX0SkQCjwRUQKRL/qwxeR/NDV1cXGjRvp6OjIdSl5I5FIUFdXRzweP+Z1KPBFpNdt3LiRiooKxo4di5nlupwBz91pbGxk48aNjBs37pjXoy4dEel1HR0dDBo0SGHfS8yMQYMGHfdfTAp8EckKhX3v6o32HPCB7+784MXV/H7VjlyXIiLSrw34wDcz7n15Lb9/S4EvIoHGxkZmzJjBjBkzGD58OKNGjdr/vrOzs0fruPHGG3nrrbeyXGnfyouTtpWJGE0dXbkuQ0T6iUGDBrFo0SIAvvvd71JeXs7f/d3fHTCPu+PuRCIHP+594IEHsl5nXxvwR/gAlSVx9rYr8EXk8NasWcOkSZP47Gc/y+TJk9myZQs33XQTDQ0NTJ48me9973v75/3whz/MokWLSKVSVFdXc9tttzF9+nTOPPNMtm/fnsO9OHb5cYRfEqdJgS/SL/3Tb5axfHNTr65z0shKvvOJyce07MqVK3nooYdoaGgA4I477qC2tpZUKsWcOXO46qqrmDRp0gHL7N27l3PPPZc77riDW2+9lfvvv5/bbrvtuPejr+XFEX5VSZymjlSuyxCRAWD8+PH7wx7gkUceob6+nvr6elasWMHy5cs/sExJSQmXXHIJALNmzWL9+vV9VW6vyo8j/EScpvbePYIQkd5xrEfi2VJWVrb/9erVq7nnnnt47bXXqK6u5rrrrjvote5FRUX7X0ejUVKpgXmAmRdH+LVlcXa2JElnPNeliMgA0tTUREVFBZWVlWzZsoXnn38+1yVlVVaP8M3s68AXAQeWADe6e68PrjFxRCXJVIa3d7RwyrCK3l69iOSp+vp6Jk2axIQJEzjhhBM466yzcl1SVpl7do6KzWwU8Aowyd3bzeyXwLPu/uChlmloaPBjuQHKmu3NXHjXy9zxqalcc9qYY65ZRHrHihUrmDhxYq7LyDsHa1czW+juDYdY5ADZ7tKJASVmFgNKgc3Z2Mj4IeWMri3hmSVbsrF6EZG8kLXAd/dNwJ3ABmALsNfd/+v985nZTWa2wMwW7NhxbL+WNTOumDGKP67ZybYmDccqInIwWQt8M6sBLgPGASOBMjO77v3zufu97t7g7g1DhvToPrwHddnMUWQc/nPp1mNeh4hIPstml86FwDp33+HuXcB/AB/K1sbGDyln3OAy5r41MH8BJyKSbdkM/A3AGWZWasG4nhcAK7K4Pc47dQh/fruR1uTAvEZWRCSbstmHPw94DHid4JLMCHBvtrYHcMmUESRTGZ5fpm4dEZH3y+pVOu7+HXef4O5T3P1z7p7M5vYaTqihrqaEJ97YlM3NiEg/N2fOnA/8iOruu+/m5ptvPuQy5eXlAGzevJmrrrrqoPOcd955HOnS8bvvvpu2trb97y+99FL27NnT09KzKi9+abtPJGJcMTO4Wme7rtYRKVjXXnstjz766AHTHn30Ua699tojLjty5Egee+yxY972+wP/2Wefpbq6+pjX15vyKvABLpsRXK3z1JtZueRfRAaAq666imeeeWb/zU7Wr1/P5s2bmTlzJhdccAH19fVMnTqVJ5988gPLrl+/nilTpgDQ3t7ONddcw8SJE7niiitob2/fP9/NN9+8f1jl73znOwD84Ac/YPPmzcyZM4c5c+YAMHbsWHbu3AnAXXfdxZQpU5gyZQp33333/u1NnDiRL33pS0yePJmLLrrogO30prwYPK27k4aWM2lEJf+5dCtfPPvEXJcjIs/dBluX9O46h0+FS+445Me1tbWcdtppPPfcc1x22WU8+uijXH311ZSUlPDEE09QWVnJzp07OeOMM/jkJz95yPvF/vCHP6S0tJQVK1awePFi6uvr9392++23U1tbSzqd5oILLmDx4sV85Stf4a677mLu3LkMHjz4gHUtXLiQBx54gHnz5uHunH766Zx77rnU1NSwevVqHnnkEe677z6uvvpqHn/8ca677gNXsR+3vDvCB/jIpGEs3LCbxpasnjIQkX6se7fOvu4cd+db3/oW06ZN48ILL2TTpk1s27btkOt4+eWX9wfvtGnTmDZt2v7PfvnLX1JfX8/MmTNZtmzZQYdV7u6VV17hiiuuoKysjPLycj71qU/xhz/8AYBx48YxY8YMILvDL+fdET7AhROHcc+Lq3lp5XY+3TA61+WIFLbDHIln02WXXcbXv/51Xn/9ddra2pg1axYPPvggO3bsYOHChcTjccaOHXvQ4ZCPZN26ddx5553Mnz+fmpoabrjhhmNazz7FxcX7X0ej0ax16eTlEf6UUZUMqyzmtysO/c0tIvmtvLycOXPm8PnPf37/ydq9e/cydOhQ4vE4c+fO5Z133jnsOs455xwefvhhAJYuXcrixYuBYFjlsrIyqqqq2LZtG88999z+ZSoqKmhubv7Aus4++2x+/etf09bWRmtrK0888QRnn312b+1uj+TlEb6Zcf6EYfzmzc10pTPEo3n5vSYiR3DttddyxRVX7O/a+exnP8snPvEJpk6dSkNDAxMmTDjs8jfffDM33ngjEydOZOLEicyaNQuA6dOnM3PmTCZMmMDo0aMPGFb5pptu4uKLL2bkyJHMnTt3//T6+npuuOEGTjvtNAC++MUvMnPmzD69e1bWhkc+Fsc6PPLBPLtkC1/++es8fvOZzDqhtlfWKSI9o+GRs6O/D4+cM2eeOAgz+OOaxlyXIiLSL+Rt4NeUFTF5ZCWvrNmZ61JERPqFvA18gLPGD+aNDbtp69RgaiJ9rT91F+eD3mjPvA78D500mK6089q6XbkuRaSgJBIJGhsbFfq9xN1pbGwkkUgc13ry8iqdfWaPrSEWMV5bt4vzTh2a63JECkZdXR0bN27kWO9iJx+USCSoq6s7rnXkdeCXFsWYPKqK+et1hC/Sl+LxOOPGjct1GfI+ed2lA3D6uFrefHcvHV3pXJciIpJTeR/4s8fW0pnO8Oa7/WM8ahGRXCmAwK8BULeOiBS8vA/86tIiTh1WwTxdqSMiBS7vAx+gYWwNizbsIZ3RJWIiUrgKIvBnnVBDczLF6u0fHMFORKRQFEzgAyx8Z3eOKxERyZ2CCPwxtaUMLi9S4ItIQSuIwDcz6sfUKPBFpKAVROAD1J9QwzuNbbrPrYgUrMIJ/DFBP/4i/QBLRApUwQT+1FFVxCLG6xvUrSMihalgAr+kKMqkkZUsWK/AF5HCVDCBD8HlmYve3UNnKpPrUkRE+lxBBf7ssbUkUxmWb2nKdSkiIn2uoAJ/xuhqABZv1IlbESk8BRX4I6oS1JYVsXyzjvBFpPAUVOCbGRNHVKhLR0QKUkEFPsDE4ZW8tbWZVFonbkWksBRe4I+oJJnKsL6xNdeliIj0qYIMfIBl6scXkQJTcIF/0tByiqIRlm7am+tSRET6VMEFflEswrS6Ko2cKSIFp+ACH4KRM5duaiKZSue6FBGRPpPVwDezajN7zMxWmtkKMzszm9vrqRmjq+lMZ3hrq255KCKFI9tH+PcA/+nuE4DpwIosb69Hpoe/uH1TQyWLSAHJWuCbWRVwDvBTAHfvdPd+kbAjqxIMLi9m0bs6cSsihSObR/jjgB3AA2b2hpn9xMzK3j+Tmd1kZgvMbMGOHTuyWM4B22TKqEqWbVbgi0jhyGbgx4B64IfuPhNoBW57/0zufq+7N7h7w5AhQ7JYzoEmj6xk9fYWOrp04lZECkM2A38jsNHd54XvHyP4AugXpoysIp1xnbgVkYKRtcB3963Au2Z2ajjpAmB5trZ3tKaFJ251j1sRKRTZvkrnb4Cfm9liYAbwz1neXo+NrEowtKJY97gVkYIRy+bK3X0R0JDNbRyTVBJr38PMMdU6wheRglGQv7TlvvPhN19l5pga3mlso7ElmeuKRESyrjADf8R02DifevXji0gBKczAr2uAtp1MK9tDNGLqxxeRglCggT8bgMS215k4ooI3NugIX0TyX2EG/pCJEC+DjfOZMbqaxRv3ksl4rqsSEcmqwgz8aAxG1cPG+Uyrq6YlmWKdbnkoInmuMAMfgn78rYuZMrQI0C0PRST/FXDgz4ZMipPTa4lHjWW65aGI5LnCDfxRwe/B4lsWcsqwCh3hi0jeK9zArxgG1WNg43wmjwyGSnbXiVsRyV+FG/gQdOtsXMCUUVXsbuti896OXFckIpI1CvymjcyqCYJetzwUkXymwAdOSa0kGjHdAUtE8lphB/7wqRAtIr55IeOHlLFii26GIiL5q7ADP1YcDqS2gIkjKnX3KxHJa4Ud+BB062x+g0lDS9i0p5297V25rkhEJCsU+HUNkGqnvmQLgI7yRSRvKfD3nbjtWgnAyq36AZaI5CcFftVoKB9G5c43qC6N68StiOQtBb4Z1M3GNi7g1GEVOsIXkbylwIegH3/X28wcnGHV1maNjS8ieUmBD/v78c8oWkdrZ5pNe9pzXJCISO9T4AOMnAkW4ZTUW4Cu1BGR/KTABygqg2GTGbp3MaArdUQkPynw96mbTWzL64yrTWhsfBHJSwr8fepmQ7KJ84fsZfFGDaImIvlHgb9PeOL2rOJ1bNrTTlOHhlgQkfzSo8A3s/FmVhy+Ps/MvmJm1dktrY/VjodENaemgl/c6sStiOSbnh7hPw6kzewk4F5gNPBw1qrKhUgE6hoY1rQEgEUbdDMUEckvPQ38jLungCuAf3P3vwdGZK+sHKmbTWznSk6tMeav35XrakREelVPA7/LzK4FrgeeDqfFs1NSDtU1AM7lQ7fy2vpduqm5iOSVngb+jcCZwO3uvs7MxgH/O3tl5cioWQCcFn+bPW1dbG9O5rggEZHe06PAd/fl7v4Vd3/EzGqACnf/lyzX1vdKamDwKYzrWAHASp24FZE80tOrdH5nZpVmVgu8DtxnZndlt7QcqZtN9a43AWflFv0AS0TyR0+7dKrcvQn4FPCQu58OXJi9snKoroFI206mlu7hlwvezXU1IiK9pqeBHzOzEcDVvHfSNj+FP8C6uHoD25uSOnErInmjp4H/PeB54G13n29mJwKrs1dWDg2ZCPEyLqh4l+Zkio27NVSyiOSHnp60/ZW7T3P3m8P3a939yuyWliPRGIyqZ0zrMgCWbNK4OiKSH3p60rbOzJ4ws+3h43Ezq+vhslEze8PMBk5XUF0DJbuWURbpUuCLSN7oaZfOA8BTwMjw8ZtwWk98FVhx9KXlUN1sLJPikkHbWaKRM0UkT/Q08Ie4+wPungofDwJDjrRQ+FfAx4CfHEeNfW9UAwBzytezZNNenbgVkbzQ08BvNLPrwu6ZqJldBzT2YLm7gW8AmUPNYGY3mdkCM1uwY8eOHpaTZRXDoHoMU301e9u7eHtHa64rEhE5bj0N/M8TXJK5FdgCXAXccLgFzOzjwHZ3X3i4+dz9XndvcPeGIUOO+EdD36mbzYiWpQAaSE1E8kJPr9J5x90/6e5D3H2ou18OHOkqnbOAT5rZeuBR4Hwz+z/HV24fqptNvGUzE8uamb9OgS8iA9/x3PHq1sN96O7fdPc6dx8LXAO85O7XHcf2+lb4A6zLh2xhngJfRPLA8QS+9VoV/dHwqRAt4szwloeb9+gHWCIysB1P4Pf40hV3/527f/w4ttX3YsUwYjrjk8EVperHF5GB7rCBb2bNZtZ0kEczwfX4+a1uNqU7l1BTjLp1RGTAO2zgu3uFu1ce5FHh7rG+KjJn6hqwVDsfG76bN9/VPW5FZGA7ni6d/BeeuD2nZD2rtjWTTKVzXJCIyLFT4B9O1WgoH8ZkX0VX2pm/bneuKxIROWYK/MMxC36A1byUykSMxxbqhigiMnAp8I+kroHIrre5aFycXy/aTGOLbmwuIgOTAv9Iwn78z43ZCcCLK7fnshoRkWOmwD+SkTPBIkzNrCIeNdZqIDURGaAU+EdSVAbDJhPZtIBJIyp5dW1PBgkVEel/FPg9MeZM2PAq549LsGTTXjq6dHmmiAw8CvyemH4tpNq5MPV70hln+ZamXFckInLUFPg9MXImDJ/GKe8+BrhueygiA5ICvyfMYNYNxHcu59yyd3hJV+qIyACkwO+pqZ+GeBlfLHmZ36/awa7WzlxXJCJyVBT4PZWohKlXcmb776mgjd8u35brikREjooC/2jMuoFYup3PJF7lz7o8U0QGGAX+0RhZD8On8oXE73hm8Wa2N3fkuiIRkR5T4B+N8OTtiI41TMys1uiZIjKgKPCP1tSr8Xgp18XnsnijbooiIgOHAv9oJSqxKVfyicif+NPydbmuRkSkxxT4x2LWjSRIMm33C7zTqMHURGRgUOAfi1H1JAdN4i+iL/L0m5tzXY2ISI8o8I+FGcVnfIHJkXdY9cbLua5GRKRHFPjHauqn6YokOGP3b3h3V1uuqxEROSIF/rFKVNF2ymV8MvonvvfYq7muRkTkiBT4x6HyrC9RZkmGvPM07p7rckREDkuBfxysroEtifFcG32R9Y3q1hGR/k2BfzzMiJ/2eaZG1vPjRx7LdTUiIoelwD9Ogz/0Odq9iGnbniCVzuS6HBGRQ1LgH69EFRtGXsJl0T/x+Ksrc12NiMghKfB7wcmX3EKZJdn96sO5LkVE5JAU+L0gMno266Jj+dDep1m/U0MtiEj/pMDvDWasqruKaZF13PL/3k9LMpXrikREPkCB30suuuYW2r2Iv4i+xM/+tD7X5YiIfIACv5dYSQ0lMz/N5bE/86fl63NdjojIByjwe9OsGyilnTGbn2N3a2euqxEROYACvzfVzaa95lSuib7Ey6t35LoaEZEDKPB7kxnFp3+B6ZG1rFr0Sq6rERE5QNYC38xGm9lcM1tuZsvM7KvZ2lZ/Epn+GbqsiLHrf0U6owHVRKT/yOYRfgr4W3efBJwB/LWZTcri9vqHkmq2jr6US/wP/HbeolxXIyKyX9YC3923uPvr4etmYAUwKlvb60+qL/oHIjjVz/0Ve1vac12OiAjQR334ZjYWmAnMO8hnN5nZAjNbsGNHfpzorKibxAsn3sbpkZU8fMeX+P2q/NgvERnYsh74ZlYOPA58zd2b3v+5u9/r7g3u3jBkyJBsl9NnLrv+Vh5Onc/Nsd/wswd/RFNHV65LEpECl9XAN7M4Qdj/3N3/I5vb6o8u/cbPeDs6nrviP+RL9zye63JEpMBl8yodA34KrHD3u7K1nf6surKS8X/9GFEyfKv1X2hp1cBqIpI72TzCPwv4HHC+mS0KH5dmcXv9U+2JbJ1zF9Mja9n22N/muhoRKWDZvErnFXc3d5/m7jPCx7PZ2l5/Nv6ca/lp+lLGr3sElqprR0RyQ7+07QORiLFk4q0szJxM5sm/gZ2rc12SiBQgBX4f+ebHp3JL51fY02mkf/E56GzLdUkiUmAU+H1kWGWCk0+ZwNe6/hrbvhJ/Rv35ItK3FPh96P7rG3g5M51/S1+OvfkwvP6/c12SiBQQBX4fikUjrL79Eu5JXckr6clknvk72Lok12WJSIFQ4PexeDTCA58/g6913cKOVAJ+eT10fOAHyCIivU6BnwPnnjKE8kEjuKXzK/ju9fDULeAaSllEskuBnyO/+G9nMt8ncEfn1bD8STLzfpzrkkQkzynwc2RYZYLrzhjDvemP8UK6Hn/+27Qs+EWuyxKRPKbAz6H/cflUfvS52fxt11/xevpEyp++ifbffAPSGllTRHqfAj/HPjp5OA//zcX8Red/54HURylZ+GMyD34Cb96a69JEJM8o8PuBKaOqWH3HZSyf/m2+2vllkhsWsv3O09m0eG6uSxORPKLA70duv2IqT2Y+zBWd36Pdixn6+JX84f/crit4RKRXxHJdgLynKBbhua+eTSrt3Pn8BC5f/09cuOZfWXvfck684T4oKs11iSIygOkIv5+ZOKKSqXVV/K8vzGHmN57jzq5PM3bTM6TvuxAa3851eSIygCnw+7FBFSWUfeSb3Nj1DZq3r8fvPQ/e+s9clyUiA5QCv5/7q3NPxE6+kI933s6y9lp45DMw958hk851aSIywCjw+zkz4/7rZ/Oxc87gys7v8iTnwe//BR6+GvZuynV5IjKA6KTtABCJGN+8ZCIXTx7OFf9fnHnR8fzfbz9E5J5p2ORPwYdugRHTc12miPRzOsIfQGaOqeH7V03n4fQFnNtxJ/d3foSu5U/Dj8+BBz8Oq56HTCbXZYpIP2Xej67xbmho8AULFuS6jH6vuaOL025/kfauNJW08v0TF3FRy6+xpk0w+BQ448sw/RqIl+S6VBHJMjNb6O4NPZpXgT9wPbdkCzf//HUAYqT42ohlnNv4C6ZG1uOlg7HZX4TZX4TyITmuVESyRYFfQFLpDJf+4A+s2tYSTnHOiKzgC9Fn+Uj0dTxajE3/DJx5Cww5Nae1ikjvU+AXoIXv7OKF5du5uqGOu3+7mqfe3MyJtpkvRJ/jLxJ/xFIdMPp0OOXi4DF0IpjlumwROU4KfGHhO7u58od/AqCGJr49fB4XReZTuWtpMEPVGDjlo0H4j/0wxBM5rFZEjpUCXwBwd+7/43r+5wuraEmmABjKbn5xfhPjGl+BtXOhqw3ipXDinOAL4OSLoHJEjisXkZ5S4MsB0hnn6cWb+ednV7CtKbl/ejGd3DJuK5cWv8kJu/5ArGlj8MGI6cGR/4lzgtcatE2k31LgyyHtaevkxy+v5Ye/e/9AbM4ptpGPxN7g6srljGlbinkGLArDJkNdA4xqCJ4HnQwR/YRDpD9Q4MsRuTvLNjfx6tpGfvfWDl5ZsxOAykSMpo4U1TTzkfJ1fGLQZsZ3rqRmz1JKvS1YuLgSRs488EugfGgO90akcCnw5Zi5O00dKX72p/U8u2QLK7c2A2BkGG+bmRF5m3NL32FcciUTIhuIEfyy16tGkxk+g+iwicHln0MmwKCTdDJYJMsU+NJrtuxtZ+PudioTceata+Qfn1xGbVkRu1o7SZBkiq1jRuRtZkTWMNnWM8a2E7Xg/ym3CFYzLgj/IaeEz6cGvwYuKsvxnonkBwW+9Al355klW/j2E0s5ZVg5JUUxNu3YRXzPOk62jZwU2cTMxHZOiWxiSNe7RL3bkM7VY8gMOpm28jGUDT0RqxkLNWOh5gRIVOVql0QGHAW+5Nyqbc185ZE3WLuzlc5UhhgpTrBtnGybOMk2cXJkE+NtM2NsO5XWdsCyXlJDpmoM0dqxwZdA9QnBF0H1WKgapTGCRLpR4Eu/s7Mlybu72tiwq43/Wr6NHc1JMhlnwogKlr29gaLmDdR2buGEyA7GRncwIrONk+I7GZrZTpzUAevqiFXRUTKUlqKhxGvqSJYOZ9CIEygdPAarHAkVI6CkRr8kloKgwJcBJ5lK87u3dvDq2kZ2tXbS1N5FU0eK0hjUZhpJNa4n0bKR4bYrfOxmuDUy3HYzxPZ+YH2dVkxb8VAyZUPJlAwiXjmUstrhxCqGQtlgKBsCpfueayESzcFeixy/owl83QBF+oXiWJSPTh7ORycPP+jn7s7Krc1sa+rgxMHlpN3pTGV4dVsz5bE02za9w6o1q4i3bmUouyjt2Ep56w4GtTYxyJYzyF7FrBn44AGOY3TEq+gsHoSV1kJJLZmSaiKltRRVDKaofBBt0QoyiRpKqwYTKx8U/AURL9VfETKg6Ahf8lZzRxfv7mpnV2snq7c3s2zjbrx9F6NirXQ0bSfStoN4RyNFyV3U+F4GWRM11kIVLVRbKzU0k7CuQ64/ZXFSRZV0xipIxspJRsrpiJaRildiiUoipVXES6uprBlEeeUg4mVVWKIKisqhuCK4UklfGnKcdIQvAlQk4kwaGQfgwycPBsYddD53pyWZYsOuNrY3J9mbyrA27bQku2hubibZ0sjweDtFnXvZtXMrnS2NWPse0q27qOhqptLaqaCNCttJBe9SY61U0E6pJQ+6ve4yREhGSkhGSuiMlpGKldFuCZKRUigqx4vKiRSV0mEJUtESYsWlJMoqSJSWU1ZeSXl5JaVllcHwF/ESiJcFv32Il0I03pvNKXkgq4FvZhcD9wBR4Cfufkc2tydyLMyMikScySOrmHwUy+1t72JnS5JEPEpxLEJxLEI8GqEznWFXexdrW9pobdrNlm3bSLbspmlPI617d1Gcaaco3UpRuo14pp3idBtFmVbiyTYS7W1URFopo5GEt1FKMnj04Mvj/dJE6LJiOiPFdFkxqUgx6WiCVCRBJpYgHS3Gowk8loBYAosXB/dPiCWweAKPFpOJFROJFkOsGOIJMtFiIvFiYvEE0XgxRYlSioqKicYTxIuLicZLiBcH6yAS018v/UzWAt/MosC/Ax8BNgLzzewpd1+erW2K9KWqkjhVJR88ik7Eo1Qm4tTVlAKDYfLJx7R+d6c5mWJvMkVnLAKpdlqam9nbtJeW5iZaWppobWmis72FaLoDT7aSTrbS2dFKV7KNaDpJebSLokySaCZJPJUk3tVBUaaTuO+hmE5KSJKwLopIUUwnxXQdthvraGTc6LQYXcRJEQseFiNlcdLhc8aipC1OxuJkInHSFscjsQMeROLBl0ckFvzVEolh0RhEirBoDIvGsWictEUhEsUicaKxOPF4nGi8CIvGg5PyFoNoFI/EwaJYJEokGidRHMciMSKRGBaNYNE4keh7n8diseARjRONRYPxpSLR/euwSAQbIF9s2TzCPw1Y4+5rAczHs2xeAAAJ/0lEQVTsUeAyQIEv0gNmRmUiTmVi35dKMdVV1dQxulfWn84EJ76TqTTtXWl2d2VIZZxkV4quzg48lSSS7iDTmcS7OsikksEXSypJKvy8qzOJp4IHqSSW7sTTndj+RzCNTIpIphPLpIhkurBMFxHvIprpIuopIulOilKtRD1FjGBa1NNESAdfFZ4mRpoowXPc0kfewT6U8ggZIqR579kxMhY8B+/DaRhOZP9nGSK0F9Uy4ZuvZL3ObAb+KODdbu83Aqe/fyYzuwm4CWDMmDFZLEdEuotGjJKiKCVFUapzXUwPuTtdaactnaars4uuVCeprk5SXV2YpyHdRTrVRbKrk2RnJ6nOJJ5Og6cg/d48eBrzDJl0imRnJ2TS4Gk8k4ZM6oD3nk4Fz5k0nk7vj3Uy6SC+w3nxDOZpLJPGPQMexrunwR0889487kAmGJHWM1iisk/aL+cnbd39XuBeCK7SyXE5ItKPmRlFMaMoFoHiOKB7NRyNbA5qvgkO+NuzLpwmIiI5kM3Anw+cbGbjzKwIuAZ4KovbExGRw8hal467p8zsFuB5gssy73f3ZdnanoiIHF5W+/Dd/Vng2WxuQ0REekY3JhURKRAKfBGRAqHAFxEpEAp8EZEC0a+GRzazHcA7x7j4YGBnL5YzUKkdAmqHgNohkM/tcIK7D+nJjP0q8I+HmS3o6ZjQ+UztEFA7BNQOAbVDQF06IiIFQoEvIlIg8inw7811Af2E2iGgdgioHQJqB/KoD19ERA4vn47wRUTkMAZ84JvZxWb2lpmtMbPbcl1PNpjZ/Wa23cyWdptWa2YvmNnq8LkmnG5m9oOwPRabWX23Za4P519tZtfnYl+OlZmNNrO5ZrbczJaZ2VfD6QXVDgBmljCz18zszbAt/imcPs7M5oX7/ItwlFrMrDh8vyb8fGy3dX0znP6WmX00N3t07MwsamZvmNnT4fuCa4Oj4u4D9kEwCufbwIlAEfAmMCnXdWVhP88B6oGl3ab9K3Bb+Po24F/C15cCzwEGnAHMC6fXAmvD55rwdU2u9+0o2mAEUB++rgBWAZMKrR3CfTCgPHwdB+aF+/hL4Jpw+o+Am8PXXwZ+FL6+BvhF+HpS+G+mGBgX/luK5nr/jrItbgUeBp4O3xdcGxzNY6Af4e+/b667dwL77pubV9z9ZWDX+yZfBvwsfP0z4PJu0x/ywKtAtZmNAD4KvODuu9x9N/ACcHH2q+8d7r7F3V8PXzcDKwhuo1lQ7QAQ7lNL+DYePhw4H3gsnP7+ttjXRo8BF1hw1+3LgEfdPenu64A1BP+mBgQzqwM+BvwkfG8UWBscrYEe+Ae7b+6oHNXS14a5+5bw9VZgWPj6UG2SN20V/jk+k+DItiDbIezKWARsJ/jSehvY4+6pcJbu+7V/n8PP9wKDGPhtcTfwDSATvh9E4bXBURnogS8ER3wER3h5z8zKgceBr7l7U/fPCqkd3D3t7jMIbh16GjAhxyX1KTP7OLDd3RfmupaBZKAHfiHfN3db2EVB+Lw9nH6oNhnwbWVmcYKw/7m7/0c4ueDaoTt33wPMBc4k6Lbad1Oj7vu1f5/Dz6uARgZ2W5wFfNLM1hN05Z4P3ENhtcFRG+iBX8j3zX0K2HeFyfXAk92m/2V4lcoZwN6wy+N54CIzqwmvZLkonDYghP2tPwVWuPtd3T4qqHYAMLMhZlYdvi4BPkJwTmMucFU42/vbYl8bXQW8FP419BRwTXgFyzjgZOC1vtmL4+Pu33T3OncfS/Dv/iV3/ywF1AbHJNdnjY/3QXA1xiqCPsxv57qeLO3jI8AWoIugj/ELBP2PLwKrgd8CteG8Bvx72B5LgIZu6/k8wUmpNcCNud6vo2yDDxN01ywGFoWPSwutHcL6pwFvhG2xFPjHcPqJBGG1BvgVUBxOT4Tv14Sfn9htXd8O2+gt4JJc79sxtsd5vHeVTkG2QU8f+qWtiEiBGOhdOiIi0kMKfBGRAqHAFxEpEAp8EZECocAXESkQCnzpU2aWNrNF4UiPr5vZh44wf7WZfbkH6/2dmRX8PUu7M7MHzeyqI88phUKBL32t3d1nuPt04JvA/3OE+asJRjrsl7r9qlOk31PgSy5VArshGCPHzF4Mj/qXmNm+UU/vAMaHfxV8P5z3H8J53jSzO7qt79PhOPGrzOzscN6omX3fzOaH4+L/t3D6CDN7OVzv0n3zd2dm683sX8NtvWZmJ4XTHzSzH5nZPOBfLRiT/9fh+l81s2nd9umBcPnFZnZlOP0iM/tzuK+/CscHwszusGC8/8Vmdmc47dNhfW+a2ctH2Cczs/9lwbjuvwWG9uZ/LBn4dHQifa0kHOUxQTDG/fnh9A7gCndvMrPBwKtm9hTBGPdTPBgoDDO7hGBI29Pdvc3MarutO+bup5nZpcB3gAsJfpW8191nm1kx8Ecz+y/gU8Dz7n67mUWB0kPUu9fdp5rZXxKMzvjxcHod8CF3T5vZvwFvuPvlZnY+8BAwA/i/9i0f1l4T7tt/By5091Yz+wfgVjP7d+AKYIK7+76hE4B/BD7q7pu6TTvUPs0ETiUY430YsBy4v0f/VaQgKPClr7V3C+8zgYfMbArBUAj/bGbnEAx3O4r3hjru7kLgAXdvA3D37vcJ2Deg2kJgbPj6ImBat77sKoLxUuYD91swINuv3X3RIep9pNvz/+w2/Vfung5ffxi4MqznJTMbZGaVYa3X7FvA3XdbMMrjJIKQhuDGPX8mGK63A/ipBXdvejpc7I/Ag2b2y277d6h9Ogd4JKxrs5m9dIh9kgKlwJeccfc/h0e8QwjGxRkCzHL3LgtGQUwc5SqT4XOa9/7fNuBv3P0DA6SFXy4fIwjUu9z9oYOVeYjXrUdZ2/7NEtyA5dqD1HMacAHB4F63AOe7+1+Z2elhnQvNbNah9in8y0bkkNSHLzljZhMIblPZSHCUuj0M+znACeFszQS3NNznBeBGMysN19G9S+dgngduDo/kMbNTzKzMzE4Atrn7fQR3TKo/xPKf6fb850PM8wfgs+H6zwN2ejBW/wvAX3fb3xrgVeCsbucDysKayoEqd38W+DowPfx8vLvPc/d/BHYQDOV70H0CXgY+E/bxjwDmHKFtpMDoCF/62r4+fAiOVK8P+8F/DvzGzJYAC4CVAO7eaGZ/tOAG7s+5+9+b2QxggZl1As8C3zrM9n5C0L3zugV9KDsIbnt3HvD3ZtYFtAB/eYjla8xsMcFfDx84Kg99l6B7aDHQxnvD8P4P4N/D2tPAP7n7f5jZDcAjYf87BH36zcCTZpYI2+XW8LPvm9nJ4bQXCe6/uvgQ+/QEwTmR5cAGDv0FJQVKo2WKHELYrdTg7jtzXYtIb1CXjohIgdARvohIgdARvohIgVDgi4gUCAW+iEiBUOCLiBQIBb6ISIFQ4IuIFIj/H4ErDdhy5JQ2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   10,    5,   33,   26,   13, 1646,    0, 2812,   11,   13, 1485,\n",
       "          14,  260,   11,   13,    0,   15,   76,  834,   11,   30,  236,   15,\n",
       "          32, 1782,   17,    0, 1290,   13,  745,   14,   27,   18, 3301,    0,\n",
       "          11,    5,    0,    5,    0,   14,   15,    0,  677,  609,   21,   15,\n",
       "        1402,   30, 1321,   11,   13,    0,   11,    5, 2056,  870,   30,  236,\n",
       "          15,   32,    0,   30,  222, 1950,   16,    5, 1280,   21,   16,    5,\n",
       "        3302,   88,  140,  654,  491, 2813,   23,  285,   16,  599,  870,   18,\n",
       "           0,   11,    5,  995,  439,    5,  731,  947,   16,   18,  328,   16,\n",
       "          18,   15,   13,    0,   11,  216,   68,   17,   13,  283,  739,   27,\n",
       "         139,   98,   70,   92, 2171,   38, 1316,   21,   14,   19,  919,   14,\n",
       "          18, 3709,  561,   11,    5,    0,    5,    0,   14,   15,   49,   16,\n",
       "         890,   11, 2592,   30,    0,    0,   19,    5, 2446,   44,   38, 2074,\n",
       "        1791, 3303,    9], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(learn.data.train_dl))\n",
    "\n",
    "# src = x[0,:]\n",
    "# targ = y[0,:]\n",
    "\n",
    "preds = learn.model(x,y)\n",
    "preds[0][0,:].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_itos = data.label_list.train.x.vocab.itos\n",
    "y_itos = data.label_list.train.y.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj what is the logic i am not talking about the justification but , rather , of the logic behind a decision that has immediately led to a xxunk of violence , including the tragic bombing in xxmaj xxunk xxmaj xxunk which produced ten victims and which constitutes a breach of xxmaj xxunk xxunk ; a decision that has led to the xxunk of a humanitarian crisis in xxmaj gaza and in the xxmaj west xxmaj bank , with no alternative plan ready to be brought into operation ; to xxmaj palestine ’s xxunk towards xxmaj iran at the very time when the breakdown of negotiations on nuclear power with that country has us xxunk the worst ; and , finally , to the political weakening of xxmaj xxunk xxmaj xxunk who , if we support him too openly , is in danger of looking like a xxunk xxunk by the xxmaj west ?\n",
      "xxbos ¿ xxmaj cuál es la lógica xxunk hablo de la justificación , sino de la xxunk que hay detrás de una decisión que ha llevado a xxunk inmediatamente la violencia , con el trágico xxunk de xxmaj xxunk xxmaj xxunk , que xxunk diez víctimas y que constituye una violación de la xxunk de xxmaj hamás ; una decisión que ha xxunk una crisis humanitaria en xxmaj gaza y en xxmaj cisjordania sin tener ningún plan alternativo para poner en marcha ; el xxunk de xxmaj palestina hacia xxmaj irán justo en el momento en el que la xxunk de negociaciones respecto a la energía nuclear con ese país nos hace temer lo peor y , por último , el debilitamiento político de xxmaj xxunk xxmaj xxunk , que está en peligro de parecer una xxunk xxunk por xxmaj occidente si lo apoyamos demasiado abiertamente ?\n",
      "xxbos ¿ xxmaj cuál es la lógica xxunk hablo de la justificación , sino de la xxunk que hay detrás de una decisión que ha llevado a xxunk inmediatamente la violencia , con el trágico xxunk de xxmaj xxunk xxmaj xxunk , que xxunk diez víctimas y que constituye una violación de la xxunk de xxmaj hamás ; una decisión que ha xxunk una crisis humanitaria en xxmaj gaza y en xxmaj cisjordania sin tener ningún plan alternativo para poner en marcha ; el xxunk de xxmaj palestina hacia xxmaj irán justo en el momento en el que la xxunk de negociaciones respecto a la energía nuclear con ese país nos hace temer lo peor y , por último , el debilitamiento político de xxmaj xxunk xxmaj xxunk , que está en peligro de parecer una xxunk xxunk por xxmaj occidente si lo apoyamos demasiado abiertamente ?\n",
      "\n",
      "xxbos xxmaj what other purpose can there be to all these proposals which we hear and which , generally speaking , are incorporated into the report , on voting changes in the xxmaj council , on changes to the number or responsibilities of xxmaj commissioners , on reduced grass roots representation in the xxup ec following the increase in the number of xxmaj member xxmaj states , other than to strengthen the position of the rich countries of the xxup eu , to strengthen the position of monopoly undertakings , the majority of which are established in those countries and to play down grass roots or national opposition to xxup eu decisions which xxunk affect the grass roots and which might even affect national interests ?\n",
      "xxbos ¿ xxmaj qué otra cosa pueden significar las propuestas que se escuchan , y que en general están recogidas en el informe , sobre los cambios en las votaciones del xxmaj consejo , sobre el cambio del número , o de las competencias , de los comisarios , sobre la disminución de la representación popular en el xxup pe tras el aumento del número de estados de la xxup ue , sino el xxunk de la posición de los países ricos de la xxup ue , el xxunk de la posición de las empresas xxunk , que en su mayoría tienen su sede en esos países , el intento de xxunk cualquier resistencia de los pueblos , o incluso de los países , a las xxunk resoluciones de la xxup ue que afectan o pueden xxunk incluso a intereses nacionales ?\n",
      "xxbos ¿ xxmaj qué otra cosa pueden significar las propuestas que se escuchan , y que en general están recogidas en el informe , sobre los cambios en las votaciones del xxmaj consejo , sobre el cambio del número , o de las competencias , de los comisarios , sobre la disminución de la representación popular en el xxup pe tras el aumento del número de estados de la xxup ue , sino el xxunk de la posición de los países ricos de la xxup ue , el xxunk de la posición de las empresas xxunk , que en su mayoría tienen su sede en esos países , el intento de xxunk cualquier resistencia de los pueblos , o incluso de los países , a las xxunk resoluciones de la xxup ue que afectan o pueden xxunk incluso a intereses nacionales ?\n",
      "\n",
      "xxbos xxmaj which xxmaj member xxmaj states are not introducing the measures necessary for this regulation to be implemented xxunk , and what measures has the xxmaj european xxmaj commission taken or is it considering taking , specifically xxunk of infringement proceedings before the xxmaj european xxmaj court of xxmaj justice to ensure that all xxmaj member xxmaj states comply with the regulation and to prevent the funds allocated being xxunk by some xxmaj states ' inability to comply with the established rules ?\n",
      "xxbos ¿ xxmaj cuáles son los xxmaj estados miembros que no están introduciendo las medidas necesarias para que el xxmaj reglamento se aplique de manera conveniente y qué medidas ha tomado o piensa adoptar la xxmaj comisión xxmaj europea , en concreto la xxunk de un procedimiento de infracción ante el xxmaj tribunal xxmaj europeo de xxmaj justicia , para asegurar el cumplimiento del xxmaj reglamento por todos los xxmaj estados miembros y evitar poner en riesgo los fondos xxunk por la incapacidad de algunos para cumplir las normas establecidas ?\n",
      "xxbos ¿ xxmaj cuáles son los xxmaj estados miembros que no están introduciendo las medidas necesarias para que el xxmaj reglamento se aplique de manera conveniente y qué medidas ha tomado o piensa adoptar la xxmaj comisión xxmaj europea , en concreto la xxunk de un procedimiento de infracción ante el xxmaj tribunal xxmaj europeo de xxmaj justicia , para asegurar el cumplimiento del xxmaj reglamento por todos los xxmaj estados miembros y evitar poner en riesgo los fondos xxunk por la incapacidad de algunos para cumplir las normas establecidas ?\n",
      "\n",
      "xxbos xxmaj what position will the xxmaj commission adopt with regard to the concerns , expressed by the xxmaj xxunk fisheries sector to xxmaj commissioner xxmaj fischler during his working visit to xxmaj xxunk , that it would be appropriate for the xxmaj agency to take on duties relating to research and the xxunk of the scientific principles governing the state of fishery resources and to consider the possible introduction of a system for the exchange of fishing quotas between xxmaj community enterprises ?\n",
      "xxbos ¿ xxmaj qué posición va a adoptar la xxmaj comisión ante las solicitudes presentadas por el sector pesquero xxunk al xxmaj comisario xxmaj fischler , durante su xxunk de trabajo a xxmaj xxunk , con respecto a la conveniencia de que esa agencia xxunk también funciones relativas a la investigación y a la mejora de los dictámenes científicos sobre el estado de los recursos pesqueros y el análisis de una posible aplicación de sistemas de intercambio de cuotas entre las empresas pesqueras comunitarias , para que , de conformidad con las propuestas del sector xxunk , se xxunk en sus responsabilidades a otras agencias como las relativas al mercado interior o a la promoción del diálogo social ?\n",
      "xxbos ¿ xxmaj qué posición va a adoptar la xxmaj comisión ante las solicitudes presentadas por el sector pesquero xxunk al xxmaj comisario xxmaj fischler , durante su xxunk de trabajo a xxmaj xxunk , con respecto a la conveniencia de que esa agencia xxunk también funciones relativas a la investigación y a la mejora de los dictámenes científicos sobre el estado de los recursos pesqueros y el análisis de una posible aplicación de sistemas de intercambio de cuotas entre las empresas pesqueras comunitarias , para que , de conformidad con las propuestas del sector xxunk , se xxunk en sus responsabilidades a otras agencias como las relativas al mercado interior o a la promoción del diálogo social ?\n",
      "\n",
      "xxbos xxmaj why is it that the proposal of the xxmaj council for the management of xxmaj northern xxunk stocks and its final resolution have the effect of dividing the fishing rights for this species into sea areas when the xxunk population is considered by the xxup xxunk as one management unit for which the xxup xxunk xxmaj advisory xxmaj committee on xxmaj fishery xxmaj management provides xxunk scientific advice and does not recommend its being divided up by sea area ?\n",
      "xxbos ¿ xxmaj cómo se entiende que la propuesta del xxmaj consejo de gestión para la población de merluza del xxmaj norte y su resolución final sea la de xxunk esta xxunk por áreas de mar cuando esta población de merluza es xxunk por el xxup xxunk como una unidad e gestión para la que el xxup xxunk del xxup xxunk da un consejo científico de gestión única y sin recomendaciones por áreas de mar ?\n",
      "xxbos ¿ xxmaj cómo se entiende que la propuesta del xxmaj consejo de gestión para la población de merluza del xxmaj norte y su resolución final sea la de xxunk esta xxunk por áreas de mar cuando esta población de merluza es xxunk por el xxup xxunk como una unidad e gestión para la que el xxup xxunk del xxup xxunk da un consejo científico de gestión única y sin recomendaciones por áreas de mar ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(5):\n",
    "    print(' '.join([x_itos[o] for o in x[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in y[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in preds[0][i,:].argmax(dim=1) if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
