{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMT (seq2seq) in fastai v1\n",
    "\n",
    "Start with this:<br>\n",
    "https://gist.github.com/ohmeow/fe91aed6267cd779946ab9f10eccdab9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATA_PATH = Path('./data/es-en')\n",
    "\n",
    "BASE = 'europarl-v7.es-en'\n",
    "en_file = DATA_PATH/f'{BASE}.en'\n",
    "es_file = DATA_PATH/f'{BASE}.es'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, split, build DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_pad_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=False, \n",
    "                        backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    \n",
    "    samples = to_data(samples)\n",
    "    x_max_len = max([len(s[0]) for s in samples])\n",
    "    y_max_len = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    x_res = torch.zeros(len(samples), x_max_len).long() + pad_idx\n",
    "    y_res = torch.zeros(len(samples), y_max_len).long() + pad_idx\n",
    "    \n",
    "    if backwards: pad_first = not pad_first\n",
    "        \n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            x_res[i,-len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,-len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            x_res[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            y_res[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: res = res.flip(1)\n",
    "        \n",
    "    return x_res, y_res\n",
    "\n",
    "class Seq2SeqDataBunch(DataBunch):\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, \n",
    "               path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1, pad_first=False, \n",
    "               device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:        \n",
    "        \"\"\"Function that transform the `datasets` in a `DataBunch` for classification.  Passes `**dl_kwargs` on to `DataLoader()`\"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        \n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/seq2seq/')\n",
    "bs = 64\n",
    "\n",
    "## load the saved data.\n",
    "data = load_data(PATH, \"full_es_en_data_spacyTok.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 255]), torch.Size([64, 252]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(data.train_dl))\n",
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([255])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][12,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2,     5,    22,    72,    10,   123,   593,  3213,    10,    17,\n",
       "            75,   404,    10,    11,  1790,    20,     5,   111,     5,  4025,\n",
       "            10,    43,     9,    11,    35,    10,    20,     5,   111,     5,\n",
       "          7307,    10,  5347,    20,     5,   124,     6,  1341,    10,     9,\n",
       "            11,     5,   333,     5, 13588,  2860,     5, 55229,    10,  6873,\n",
       "          2743,    10, 13823,    20,     5,   124,     6,  2287,    10,    20,\n",
       "             5,   111,     5,  9858,     5, 10164,    10,    13,    31,   561,\n",
       "            50,  5213,    22,    23,   302,   383,   231,    10,    16,     9,\n",
       "           127,  1569,    36,    12,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1], device='cuda:0'),\n",
       " tensor([    5,    22,    72,    10,   123,   593,  3213,    10,    17,    75,\n",
       "           404,    10,    11,  1790,    20,     5,   111,     5,  4025,    10,\n",
       "            43,     9,    11,    35,    10,    20,     5,   111,     5,  7307,\n",
       "            10,  5347,    20,     5,   124,     6,  1341,    10,     9,    11,\n",
       "             5,   333,     5, 13588,  2860,     5, 55229,    10,  6873,  2743,\n",
       "            10, 13823,    20,     5,   124,     6,  2287,    10,    20,     5,\n",
       "           111,     5,  9858,     5, 10164,    10,    13,    31,   561,    50,\n",
       "          5213,    22,    23,   302,   383,   231,    10,    16,     9,   127,\n",
       "          1569,    36,    12,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][12,:-1], b[1][12,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541, 58838)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), len(data.label_list.train.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35541,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'the',\n",
       "  ',',\n",
       "  '.',\n",
       "  'of',\n",
       "  'to',\n",
       "  'and',\n",
       "  'in',\n",
       "  'that',\n",
       "  'a',\n",
       "  'is',\n",
       "  'we'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.x.vocab.itos), data.label_list.train.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58838,\n",
       " ['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep',\n",
       "  'de',\n",
       "  ',',\n",
       "  'la',\n",
       "  '.',\n",
       "  'que',\n",
       "  'en',\n",
       "  'el',\n",
       "  'y',\n",
       "  'a',\n",
       "  'los',\n",
       "  'las'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label_list.train.y.vocab.itos), data.label_list.train.y.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model for Seq2Seq\n",
    "\n",
    "Big help from this link from the old course + looking at the `Transformer` code and adapting <br>\n",
    "https://github.com/kheyer/ML-DL-Projects/blob/master/Seq2Seq%20Transformer/Transformer.ipynb\n",
    "\n",
    "and here:<br>\n",
    "https://nbviewer.jupyter.org/github/fastai/fastai/blob/6ba17b21599a6fc441794ffd130bc31b5333b4a0/courses/dl2/translate.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "    \n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], \\\n",
    "        requires_grad=False).cuda()\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "                \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.2):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model).cuda()\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, 255)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, 252)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def reset(self): pass\n",
    "    def forward(self, src, trg, src_mask=None, trg_mask=None):\n",
    "        if src_mask is None:\n",
    "            src_mask, trg_mask = create_masks(src, trg)\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return [output, output, output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flip sign on this?  is 1/0 different for our masking convention?\n",
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    np_mask =  (torch.from_numpy(np_mask) == 0).cuda()\n",
    "\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    \n",
    "    src_mask = (src != 1).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != 1).unsqueeze(-2)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = nopeak_mask(size).cuda()\n",
    "\n",
    "        trg_mask = trg_mask & np_mask\n",
    "        \n",
    "    else:\n",
    "        trg_mask = None\n",
    "        \n",
    "    return src_mask, trg_mask\n",
    "\n",
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 300\n",
    "heads = 10\n",
    "N = 6\n",
    "\n",
    "src_vocab = len(data.label_list.train.x.vocab.itos)\n",
    "trg_vocab = len(data.label_list.train.y.vocab.itos)\n",
    "model = to_device(Transformer(src_vocab, trg_vocab, d_model, N, heads), defaults.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedder(\n",
       "      (embed): Embedding(35541, 300)\n",
       "    )\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedder(\n",
       "      (embed): Embedding(58838, 300)\n",
       "    )\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (norm_1): Norm()\n",
       "        (norm_2): Norm()\n",
       "        (norm_3): Norm()\n",
       "        (dropout_1): Dropout(p=0.1)\n",
       "        (dropout_2): Dropout(p=0.1)\n",
       "        (dropout_3): Dropout(p=0.1)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (linear_2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Norm()\n",
       "  )\n",
       "  (out): Linear(in_features=300, out_features=58838, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    \"Include the target in the training loop for Decoder mask\"\n",
    "    learn:Learner\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target[:,:-1]),\n",
    "                'last_target':last_target[:,1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLearner(RNNLearner):\n",
    "    \"Subclass of RNNLearner for predictions using Seq2Seq\"\n",
    "    \n",
    "    def predict(self, text:str, n_words:int=1, no_unk:bool=True, temperature:float=1., min_p:float=None, sep:str=' ',\n",
    "                decoder=decode_spec_tokens):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        ## handle predictions for Seq2Seq\n",
    "        set_trace()\n",
    "        ds = self.data.single_dl.dataset\n",
    "        self.model.reset()\n",
    "        xb,yb = self.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(n_words): #progress_bar(range(n_words), leave=False):\n",
    "            res = self.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            #if len(new_idx) == 0: self.model[0].select_hidden([0])\n",
    "            if no_unk: res[self.data.vocab.stoi[UNK]] = 0.\n",
    "            if min_p is not None: res[res < min_p] = 0.\n",
    "            if temperature != 1.: res.pow_(1 / temperature)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        return text + sep + sep.join(decoder(self.data.vocab.textify(new_idx, sep=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(Pdb) output.shape\n",
    "torch.Size([16, 251, 58838])\n",
    "(Pdb) src.shape\n",
    "torch.Size([16, 255])\n",
    "(Pdb) trg.shape\n",
    "torch.Size([16, 251])\n",
    "'''\n",
    "\n",
    "def seq2seq_loss(input, target):\n",
    "#     sl,bs = target.size()\n",
    "#     sl_in,bs_in,nc = input.size()\n",
    "    bs,sl = target.size()\n",
    "    bs_in,sl_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:,:sl,:]\n",
    "    if input.shape[0] != target.shape[0]:\n",
    "        set_trace()\n",
    "    return F.cross_entropy(input.view(-1,nc), target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Seq2SeqLearner(data, model, **{'alpha':0,'beta':0}, callbacks=[AppendBatchTargs()], loss_func=CrossEntropyFlat())\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'67,318,514'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in learn.model.parameters() if p.requires_grad)\n",
    "f'{total_params:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 16  ## 64 fails to load.  Prob. too big embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 2:09:32 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>3.302774</th>\n",
       "    <th>4.356208</th>\n",
       "    <th>2:09:32</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12,  22, 299,  35,  12,  12,  12,  12, 209,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "         12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(learn.data.valid_dl))\n",
    "preds = learn.model(x,y)\n",
    "preds[0][0,:].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_itos = data.label_list.train.x.vocab.itos\n",
    "y_itos = data.label_list.train.y.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj the xxmaj commission can not accept amendments 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 , 239 , 240 ,\n",
      "xxbos xxmaj la xxmaj comisin no puede aceptar las enmiendas 1 , 2 , 3 , 5 , 6 , 7 , 9 , 12 , 13 , 15 , 17 , 22 , 23 , 24 , 25 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 35 , 37 , 38 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 51 , 52 , 54 , 55 , 56 , 57 , 58 , 66 , 69 , 70 , 71 , 75 , 77 , 80 , 82 , 84 , 85 , 86 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 98 , 99 , 100 , 106 , 109 , 110 , 111 , 112 , 113 , 114 , 118 , 129 , 131 , 133 , 134 , 135 , 136 , 137 , 138 , 143 , 150 , 151 , 152 , 153 , 154 , 155 , 156 , 160 , 162 , 164 , 166 , 167 , 168 , 169 , 170 , 173 , 174 , 177 , 178 , 179 , 182 , 189 , 206 , 212 , 214 , 216 , 218 , 219 , 222 , 223 , 224 , 225 , 226 , 227 , 228 , 229 , 230 , 231 , 232 , 233 , 234 , 237 , 238 ,\n",
      ". por votacin comisin . . . . enmiendas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "xxbos xxmaj the xxmaj commission can accept the following amendments : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 and 164 to 209 .\n",
      "xxbos xxmaj la xxmaj comisin puede aceptar las siguientes enmiendas : 2 , 3 , 4 , 7 , 9 , 12 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 23 , 24 , 25 , 26 , 27 , 29 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 44 , 45 , 46 , 47 , 48 , 49 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 71 , 72 , 73 , 74 , 77 , 78 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 90 , 94 , 95 , 96 , 97 , 99 , 100 , 101 , 102 , 103 , 104 , 106 , 107 , 108 , 111 , 112 , 114 , 115 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , 125 , 126 , 128 , 137 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , 146 , 147 , 148 , 149 , 150 , 151 , 152 , 153 , 154 , 155 , 157 , 158 y 164 a 209 .\n",
      ". por votacin comisin . . . enmiendas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . medianas . las .\n",
      "\n",
      "xxbos xxmaj the next item is the oral question to the xxmaj commission ( xxup b5 - 0206 / 2000 ) by xxmaj mr xxmaj lannoye , xxmaj mrs xxmaj auroi , xxmaj mr xxmaj bouwman , xxmaj mr xxmaj bowe , xxmaj mrs xxmaj cerdeira xxmaj morterero , xxmaj mrs xxmaj corbey , xxmaj mr xxmaj costa xxmaj paolo , xxmaj mr xxmaj deprez , xxmaj mr xxmaj desama , xxmaj mrs xxmaj gonzlez xxmaj lvarez , xxmaj mrs xxmaj guy - xxmaj quint , xxmaj mr xxmaj izquierdo xxmaj collado , xxmaj mr xxmaj jonckheer , xxmaj mrs xxmaj korhola , xxmaj mr xxmaj kreissl - xxmaj drfler , xxmaj mrs xxmaj lienemann , xxmaj mrs xxmaj lucas , xxmaj mrs mckenna , xxmaj mrs xxmaj maes , xxmaj mr xxmaj martnez xxmaj martnez , xxmaj mr xxmaj papayannakis , xxmaj mrs xxmaj patrie , xxmaj mr xxmaj arvidsson , xxmaj mr xxmaj puerta , xxmaj mr xxmaj ries , xxmaj mr xxmaj rod , xxmaj mr de xxmaj roo , xxmaj mrs xxmaj sandbk , xxmaj mrs xxmaj schroedter , xxmaj mrs xxmaj sornosa xxmaj martnez , xxmaj mr xxmaj staes , xxmaj mr xxmaj sterckx , xxmaj mrs xxmaj terrn i xxmaj cus , xxmaj mrs xxmaj van xxmaj brempt , xxmaj mr xxmaj vander xxmaj taelen , xxmaj mrs xxmaj van xxmaj lancker and xxmaj mr xxmaj ducarme , regarding night flights and noise pollution around airports .\n",
      "xxbos xxmaj de conformidad con el orden del orden del da se procede a la pregunta oral formulada a la xxmaj comisin por los diputados xxmaj lannoye , xxmaj auroi , xxmaj bouwman , xxmaj bowe , xxmaj cerdeira xxmaj morterero , xxmaj corbey , xxmaj costa xxmaj paolo , xxmaj deprez , xxmaj desama , xxmaj gonzlez xxmaj lvarez , xxmaj guy - xxmaj quint , xxmaj izquierdo xxmaj collado , xxmaj jonckheer , xxmaj korhola , xxmaj kreissl - xxmaj drfler , xxmaj lienemann , xxmaj lucas , mckenna , xxmaj maes , xxmaj martnez xxmaj martnez , xxmaj papayannakis , xxmaj patrie , xxmaj arvidsson , xxmaj puerta , xxmaj ries , xxmaj rod , de xxmaj roo , xxmaj sandbk , xxmaj schroedter , xxmaj sornosa xxmaj martnez , xxmaj staes , xxmaj sterckx , xxmaj terrn i xxmaj cus , xxmaj van xxmaj brempt , xxmaj vander xxmaj taelen , xxmaj van xxmaj lancker , xxmaj ducarme , sobre los vuelos nocturnos y las molestias sonoras en las cercanas de los aeropuertos ( xxup b5 - 0206 / 2000 ) .\n",
      ". por . con el orden del da del da . procede . las votacin . . . las votacin acta . escrito xxmaj . acta . . acta . . acta . . acta . . acta . acta . . acta . . acta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . la . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . la . . votacin xxunk . . . 2 )\n",
      "\n",
      "xxbos - xxup a5 - 0212 / 2004 by xxmaj mr xxmaj mulder , on the discharge to the xxmaj european xxmaj agency for xxmaj reconstruction for the financial year 2002 ( xxup c5 - 0632 / 2003  2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for xxmaj safety and xxmaj health at xxmaj work for the financial year 2002 ( xxup c5 - 0636 / 2003  2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj environment xxmaj agency for the financial year 2002 ( xxup c5 - 0635 / 2003  2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj agency for the xxmaj evaluation of xxmaj medicinal xxmaj products for the financial year 2002 ( xxup c5 - 0638 / 2003  2003 / xxup xxunk ) ) ; on the discharge to the xxmaj translation xxmaj centre for the xxmaj bodies of the xxmaj european xxmaj union for the financial year 2002 ( xxup c5 - 0637 / 2003  2003 / xxup xxunk ) ) ; on the discharge to the xxmaj european xxmaj centre for the xxmaj development of xxmaj vocational xxmaj training for the financial year 2002 ( xxup c5 - 0630 / 2003  2003 / xxup xxunk ) ) ; on the discharge to xxmaj eurojust\n",
      "xxbos xxmaj fundacin xxmaj europea para la xxmaj mejora de las xxmaj condiciones de xxmaj vida y de xxmaj trabajo ( xxup c5 - 0631 / 2003  2003 / xxup xxunk ) ) ; 10 . xxmaj observatorio xxmaj europeo de las xxmaj drogas y las xxmaj toxicomanas ( xxup c5 - 0634 / 2003  2003 / xxup xxunk ) ) ; 11 .\n",
      ". por . aplausos . la xxmaj aplausos . la . unin . la unin . la la unin . votacin ue ) . ) . ) ) . xxunk ) ) aplausos . aplausos ) . . aplausos . . . aplausos ) votacin xxunk - . ) . ) ) . xxunk ) )\n",
      "\n",
      "xxbos xxmaj oral question ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) by xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj jos xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj grard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernndez xxmaj martn , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj xxunk xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj sen  xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arbura , xxmaj jos xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj mara xxmaj antonia xxmaj avils xxmaj perea , xxmaj jos xxmaj javier xxmaj poms xxmaj ruiz , xxmaj bartho xxmaj pronk and xxmaj lennart xxmaj sacrdeus - xxmaj media concentration and pluralism\n",
      "xxbos xxmaj pregunta oral ( xxup xxunk / 02 - xxup b5 - 0502 / 02 ) de xxmaj xxunk xxmaj segni , xxmaj william xxmaj abitbol , xxmaj teresa xxmaj almeida xxmaj garrett , xxmaj guido xxmaj bodrato , xxmaj juan xxmaj jos xxmaj bayona de xxmaj perogordo , xxmaj jean - xxmaj louis xxmaj bourlanges , xxmaj luigi xxmaj cocilovo , xxmaj gerard xxmaj collins , xxmaj thierry xxmaj cornillet , xxmaj paul xxmaj coteaux , xxmaj brian xxmaj crowley , xxmaj luigi xxmaj xxunk xxmaj de xxmaj xxunk , xxmaj grard xxup xxunk xxmaj deprez , xxmaj giorgos xxmaj dimitrakopoulos , xxmaj carlo xxmaj fatuzzo , xxmaj fernando xxmaj fernndez xxmaj martn , xxmaj xxunk xxmaj ferrer , xxmaj jim xxmaj fitzsimons , xxmaj konstantinos xxmaj hatzidakis , xxmaj liam xxmaj hyland , xxmaj florence xxmaj kuntz , xxmaj franco xxmaj xxunk , xxmaj mario xxmaj clemente xxmaj xxunk , xxmaj reinhold xxmaj messner , xxmaj juan xxmaj ojeda xxmaj sanz , xxmaj sen  xxmaj neachtain , xxmaj marcelino xxmaj oreja xxmaj arbura , xxmaj jos xxmaj pacheco xxmaj pereira , xxmaj giuseppe xxmaj xxunk , xxmaj mara xxmaj xxunk xxmaj avils xxmaj perea , xxmaj jos xxmaj javier xxmaj poms xxmaj ruiz , xxmaj bartho xxmaj pronk y xxmaj lennart xxmaj sacrdeus - xxmaj concentracin y pluralismo de los medios de comunicacin\n",
      ". por n votacin xxunk ) xxunk ) . xxunk - xxunk ) 2001 ) votaciones aplausos ) xxunk ) aplausos ) aplausos ) . aplausos ) aplausos . xxunk ) . xxunk . xxunk ) . xxunk . xxunk . xxunk ) la xxunk ) . xxunk - . xxunk xxmaj xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk . xxunk ) . xxunk . xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) xxunk xxunk ) . xxunk . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk . xxunk ) . xxunk . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk . xxunk ) xxunk ) . xxunk ) . xxunk ) . xxunk ) xxunk ) xxunk ) . xxunk . xxunk ) xxunk ) . xxunk ) xxunk ) . xxunk ) xxunk ) xxunk . xxunk ) . xxunk . xxunk xxmaj xxunk . xxunk ) . xxunk . xxunk ) . xxunk ) xxunk . . xxunk . . . sesiones derechos . trabajo .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(5):\n",
    "    print(' '.join([x_itos[o] for o in x[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in y[i,:] if o != 1]))\n",
    "    print(' '.join([y_itos[o] for o in preds[0][i,:].argmax(dim=1) if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Transformer' object has no attribute 'encode_source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-90bde4bf14b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastaiv1_dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Transformer' object has no attribute 'encode_source'"
     ]
    }
   ],
   "source": [
    "inp, src_mask = learn.model.encode_source(x[i,:].unsqueeze(0))\n",
    "i,x.shape,inp.shape,src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = learn.model.decode_target(inp, src_mask, y[i,:].unsqueeze(0))\n",
    "learn.model.tgt_word_prj(targ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.tgt_word_prj(targ).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x, y):\n",
    "        #encode layers\n",
    "        inp, src_mask = self.encode_source(x)\n",
    "        targ = self.decode_target(inp, src_mask, y)\n",
    "        decoded = self.tgt_word_prj(targ) * self.x_logit_scale\n",
    "        return [decoded, inp, targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory, src_mask = learn.model.encode_source(x[i,:].unsqueeze(0))\n",
    "# ys = torch.ones(1, 1).fill_(learn.data.vocab.stoi[BOS]).type_as(x.data)\n",
    "# ys = torch.ones(1, 1).fill_(42).type_as(x.data)\n",
    "\n",
    "## make the y's side right!!! other wise POS encoding is wrong!\n",
    "ys = torch.ones(1, 252).type_as(x.data)\n",
    "ys[0][0] = 2\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=3\n",
    "for _ in range(max_len-1):\n",
    "    out = learn.model.decode_target(memory, src_mask, ys)[:,-1,:] #latest word estimate, can't change history.\n",
    "    prob = F.softmax(learn.model.tgt_word_prj(out),dim=-1)\n",
    "    next_i = learn.model.tgt_word_prj(out).argmax(dim=-1).item()\n",
    "    ys = torch.cat([ys, torch.ones(1,1).type_as(x.data).fill_(next_i)],dim=1)\n",
    "    print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob, torch.multinomial(prob,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = learn.model.decode_target(memory, src_mask, y[i,:].unsqueeze(0))\n",
    "learn.model.tgt_word_prj(targ).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow modification of prior words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory, src_mask = learn.model.encode_source(x[i,::].unsqueeze(0))\n",
    "ys = torch.ones(1, 1).fill_(learn.data.vocab.stoi[BOS]).type_as(x.data)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = learn.model.decode_target(memory, src_mask, ys)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.tgt_word_prj(out).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(learn.model.tgt_word_prj(out),dim=-1)\n",
    "next_i = learn.model.tgt_word_prj(out).argmax(dim=-1).item()\n",
    "ys = torch.cat([ys, torch.ones(1,1).type_as(x.data).fill_(next_i)],dim=1)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.tgt_word_prj(learn.model.decode_target(memory, src_mask, ys)).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multinomial(prob.squeeze(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.tgt_word_prj(out).argmax(dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=10\n",
    "for i in range(max_len-1):\n",
    "\n",
    "    out = model.decoder(Variable(ys), memory, src_mask, Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
    "    prob = F.softmax(model.out(out[:, -1]))\n",
    "    #_, next_word = torch.max(prob, dim = 1)\n",
    "    next_word = torch.multinomial(prob, 1)\n",
    "    next_word = next_word.data[0][0]\n",
    "    ys = torch.cat([ys, \n",
    "                    torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to separate encoder/decoder parts.\n",
    "### Tranaslation will be:\n",
    "# * Set state from src sentence in encoder (torch.no_grad() to keep state?)\n",
    "# * start with xxbos token\n",
    "# * proceed through each step with next word (example below)\n",
    "# * OR:  beam_search() to get best set of next words up to end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can we use this encoder as a LM for english??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 fasta.ai1 DEV",
   "language": "python",
   "name": "fastai1_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
